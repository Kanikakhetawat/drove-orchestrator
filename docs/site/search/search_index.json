{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Drove is a container orchestrator built at PhonePe. It is focussed on simplicity, container performance and easy operations.</p> <p></p>"},{"location":"#features","title":"Features","text":"<p>The following sections go over the features.</p>"},{"location":"#functional","title":"Functional","text":"<ul> <li>Application (service) and application container lifecycle management including mandated readiness checks, health checks, pre-shutdown hooks to enable operators to take containers out of rotation easily and shut them down ggracefully if needed.</li> <li>Ensures the required(specified) number of containers will always be present in the cluster. It will detect failures across the cluster and bring containers up/down to maintain required instance count.</li> <li>Provides endpoint information to be consumed by routers like nixy+nginx/traefik etc to expose containers over vhost.</li> <li>Supports short lived container based tasks. This help folks build newer systems that can spin up containers as needed on the cluster. (See epoch).</li> <li>Provides functionality for real-time log streaming and log download for all instances.</li> <li>Log generation is handled by Drove in a file layout suitable for existing log shipping mechanisms as well as for streaming to rsyslog servers (if needed).</li> <li>Provides a functional read-only web-based console for checking cluster, application, task and instance states, log streaming etc.</li> <li>Provides APIs for both read and write operations</li> <li>Supports discovery for sibling containers to support dynamic cluster reconfiguration in frameworks like hazelcast.</li> <li>Support extra metadata in the form of tags on instances. This can be used in external systems for routing or other use-cases as this information is avaliable in endpoint as well.</li> <li>CLI system for easy deployments and app/task lifecycle management.</li> <li>NGinx based router called drove-nixy for efficient communication with the cluster itself and containers deployed on it.</li> </ul>"},{"location":"#operations","title":"Operations","text":"<ul> <li>Only two components (controller and executor) to make a cluster (plus Zookeeper for coordination, drove-nixy for routing if needed).</li> <li>All components dockerised to allow for easy deployment as well as upgrades</li> <li>Simple single file YAML based configuration for the controller and executor. </li> <li>Cluster can be set to maintenance mode where it pauses making changes to the cluster and turns off safeguards around ensuring the required number of containers get reported from the executor nodes. This will allow the SRE team to do seamless software updates across the whole cluster in a few minutes,  irrespective of the size.</li> <li>Blacklisting of the executor nodes will automatically move all the running application containers to other nodes and prevent any further allocations to this node. This allows the node to be taken down for maintenance that needs longer periods of time to complete OS/patch application, hardware maintenance etc.</li> <li>Detect and kill any zombie container nodes. On mesos, SRE team needs to be involved to manually kill such containers.</li> </ul>"},{"location":"#performance","title":"Performance","text":"<ul> <li>Scheduler needs to be aware of NUMA hardware topology of the node and prevent containers from being split across nodes.</li> <li>Scheduler will pin containers to specific cores on a NUMA node so as to stop containers from stepping on each other\u2019s toes during peak hours and allow them to fully utilise the multi-level caches associated with the allocated CPU cores. Some balance is anyways gained by enabling hyper-threading on the executor nodes. This should be sufficient to provide a significant boost to the application performance.</li> <li>Allows for specialised nodes in the cluster. For example, there might be nodes with GPU available. We would want to run ML models that can utilise such hardware rather than allocate generic service containers on such nodes. To this end, the scheduler supports tagging and allows for containers to be explicitly mapped to tagged nodes.</li> <li>Allows for different placement policies to provide some flexibility to users in where they want to place their container nodes. This sometimes helps developers deploy specific apps to specific nodes where they might have been granted special privileges to perform deeper than usual investigations of running service containers (for example, take heap-dumps to specific mounted volumes etc).</li> <li>Allows for configuration injection at container startup. Such configuration can be stream in as part of the dpeloyment specification, mounted in from executor hosts or fetched via API calls by the controllers or executors.</li> <li>Provides provisions to allow for extension of the scheduler to implement different scheduling algorithms in the code later on.</li> <li>Sometimes, NUMA localization and cpu pinning are overkill for clusters that don't need to extract the last bit of performance. For example, testing/staging clusters. To this end, drove supports the following features:<ul> <li>Allows turning off NUMA and core pinning at executor level</li> <li>Allows to specify multipliers for available CPU/memory to accommodate for over provisioning on the cluster.</li> </ul> </li> <li>Because the above are set at an executor level, the cluster can have different types of nodes with different required performance characteristics appropriately tagged. Relevant apps can be deployed based on performance requirements.</li> </ul>"},{"location":"#resilience","title":"Resilience","text":"<ul> <li>Small number of moving pieces. Keeps the minimal amount of dependencies in the system. This reduces the exposure for failures by effectively reducing the number of external dependencies and possible failure points.</li> <li>Controller stores state on external system (Zookeeper) for now.</li> <li>Executor stores all container specific state in container metadata itself. No other state is maintained/needed by executor.</li> <li>Containers keep running even when most of the system is down. This means even when the cluster coordinators, executors, state storage etc are down, the already deployed containers keep on running as is. If a service discovery mechanism is implemented properly, this effectively protects the system against service disruptions even in the face of failure of critical cluster components. At PhonePe we use Ranger for service discovery. </li> <li>Container state reconciliation is part of the executor system, so that executor service can be restarted easily without affecting application or task deployments. In other words, the executor needs to recognise the containers started by itself on restarts and report their state as usual to the controller.</li> <li>Keeps things as simple as possible. Drove uses a few simple constructs (scale up/scale down) and implement all application/task features using that.</li> <li>Multi-mode cluster messaging ensures that faster updates will be sent to controller via sync channels, while the controller(s) keep refreshing the cluster state periodically irrespective of the last synced data. Drove assumes that communication failures would happen. Even if new changes can\u2019t be propagated from executor to controller, it tries to keep existing topology as updated as possible.</li> <li>Built in safeguards to detect and kill any rogue (zombie) container instances that have remained back for some reason (maybe some bug in the orchestrator etc).</li> <li>Controller is highly available with one leader active at a time. Any communication issues with zookeeeper will leader to quick death of the controller so that another controller can take up it's place as quickly as possible.</li> <li>Leader can be tracked using the <code>ping</code> api and is used by components such as drove-nixy to provide a Virtual Host that can be used to interact with the cluster via the ui or the CLI and other tools.</li> </ul>"},{"location":"#security","title":"Security","text":"<ul> <li>Clearly designate roles for read and write operations. Write operations include cluster maintenance and app and task lifecycle maintenance.</li> <li>Authentication system is easily extensible</li> <li>Supports basic auth as the minimal auth requirement. User credentials stored in bcrypt format in controller config files.</li> <li>Support a no auth mode for starter clusters</li> <li>Provides audit logs for events in the system. Such logs can get aggregated and/or shipped out  independently by existing log aggregation systems like logrotate-+rsync or (r)syslog etc by configuring the appropirate loggers in the controller configuration file.</li> <li>Separate authentication system for intra-cluster authentication and for edge. This will mean that even if external auth is compromised (or vice versa), the system keeps working as is.</li> <li>Shared secret is used for intra cluster authentication.</li> <li>Dynamically generated tokens are injected into container instances for seamless sibling discovery. This provides a way for developers to implement clustering mechanisms for frameworks like Hazelcast (provided already).</li> </ul>"},{"location":"#observability","title":"Observability","text":"<ul> <li>Real-time event stream from the controller can be used for any other event driven system like nixy etc to refresh upstream topology.</li> <li>Metrics available on admin ports for both the controllers and executors. Something like telegraf can be used to collect and send them to the centralised metrics management system of your choice. (At PhonePe we use telegraf, which pushed the metrics to our custom metrics collection service backed by a modified version of OpenTSDB. We use grafana to visualize the same metrics).</li> <li>Published metrics from controllers includes system health metrics around themselves.</li> <li>Published metrics from executors contains system health metrics as well as other metrics around the containers running on them. This includes but is not limited to CPU, Memory and network usage.</li> </ul>"},{"location":"#unsupported-features","title":"Unsupported Features","text":"<ul> <li>Auto-scaling of containers: In PhonePe we have an extensive metrics ingestion system and an auto-scaler that works on a proprietary algorithm to scale containers up and down based on the same. This works independent of the orchestration system in play (we were on Drove and Mesos both at the same time during the transition period) and calls apis on the deployment system that handles scaling operations independently. Any implementation at the orchestration level will not work as the contributors to the metrics might be running on different clusters and scaling them independently will bring in more complexities rather than solving for simplicity.</li> <li>Network level traffic control: At PhonePe network security is handled at VRF level and container level access control is not needed. All services are already integrated with the OAuth2 compliant internal authentication and authorization system and perform security checks for the same at the application layer. As a matter of fact, we want containers to be as close to the raw network level as possible to ensure we can extract the highest level of network performance possible, other things being constant.</li> <li>End to end configuration management: At this point of time, app/task configuration is maintained independently at PhonePe, subject to our apporval workflows based on the compliance domain for the application, can be static or dynamic and may be tied to deployments.</li> <li>Multi-DC clusters - We have not tested a single Drove cluster spanning across multiple data centers.</li> </ul>"},{"location":"#terminology","title":"Terminology","text":"<p>Before we delve into the details, let's get acquainted with the required terminology:</p> <ul> <li>Application - A service running on the cluster. Such a service can have an exposed port and will have an automatically configured virtual host on Drove Gateway.</li> <li>Task - A transient container based task.</li> <li>Controller Nodes - The brains of the cluster. Only one cluster is the leader and hence the decision maker in the system.</li> <li>Executor Nodes - The workhorse nodes of the cluster where the actual containers are run.</li> <li>Drove CLI - A command line client to interact with the cluster.</li> <li>Drove Gateway - Used to provide ingress to the leader and containers running on the cluster.</li> <li>Epoch - A cron type scheduler to spin up tasks on a Drove cluster based on pre-defined schedules.</li> </ul>"},{"location":"#github-repositories","title":"Github Repositories","text":"<ul> <li>Uber Repo - https://github.com/PhonePe/drove-orchestrator</li> <li>Drove Orchestrator Code - https://github.com/PhonePe/drove</li> <li>Drove CLI - https://github.com/PhonePe/drove-cli</li> <li>Drove Gateway - https://github.com/PhonePe/drove-nixy</li> <li>Epoch - https://github.com/PhonePe/epoch</li> </ul>"},{"location":"#license","title":"License","text":"<p>Apache 2</p>"},{"location":"apis/","title":"Introduction","text":"<p>This section lists all the APIs that a user can communicate with.</p>"},{"location":"apis/#making-an-api-call","title":"Making an API call","text":"<p>Use a standard HTTP client in the language of your choice to make a call to the leader controller (the cluster virtual host exposed by drove-nixy-nginx).</p> <p>Tip</p> <p>In case you are using Java, we recommend using the drove-client library along with the http-transport.</p> <p>If multiple controllers endpoints are provided, the client will track the leader automatically. This will reduce your dependency on drove-nixy.</p>"},{"location":"apis/#authentication","title":"Authentication","text":"<p>Drove uses basic auth for authentication. (You can extend to use any other auth format like OAuth). The basic auth credentials need to be sent out in the standard format in the <code>Authorization</code> header.</p>"},{"location":"apis/#response-format","title":"Response format","text":"<p>The response format is standard for all API calls:</p> <pre><code>{\n    \"status\": \"SUCCESS\",//(1)!\n    \"data\": {//(2)!\n        \"taskId\": \"T0012\"\n    },\n    \"message\": \"success\"//(3)!\n}\n</code></pre> <ol> <li><code>SUCCESS</code> or <code>FAILURE</code> as the case may be.</li> <li>Content of this field is contextual to the response.</li> <li>Will contain <code>success</code> if the call was successful or relevant error message.</li> </ol> <p>Warning</p> <p>APIs will return relevant HTTP status codes in case of error (for example <code>400</code> for validation errors, <code>401</code> for authentication failure). However, you must always ensure that the <code>status</code> field is set to <code>SUCCESS</code> for assuming the api call is succesful, even when HTTP status code is <code>2xx</code>.</p> <p>APIs in Drove belong to the following major classes:</p> <ul> <li>Application Management</li> <li>Task Management</li> <li>Cluster Management</li> <li>Log Access</li> </ul> <p>Tip</p> <p>Response models for these apis can be found in drove-models</p> <p>Note</p> <p>There are no publicly accessible APIs exposed by individual executors.</p>"},{"location":"apis/application/","title":"Application Management","text":""},{"location":"apis/application/#issue-application-operation-command","title":"Issue application operation command","text":"<p><code>POST /apis/v1/applications/operations</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/operations' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4=' \\\n--data '{\n    \"type\": \"SCALE\",\n    \"appId\": \"TEST_APP-1\",\n    \"requiredInstances\": 1,\n    \"opSpec\": {\n        \"timeout\": \"1m\",\n        \"parallelism\": 20,\n        \"failureStrategy\": \"STOP\"\n    }\n}'\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"appId\": \"TEST_APP-1\"\n    },\n    \"message\": \"success\"\n}\n</code></pre></p> <p>Tip</p> <p>Relevant payloads for application commands can be found in application operations section.</p>"},{"location":"apis/application/#cancel-currently-running-operation","title":"Cancel currently running operation","text":"<p><code>POST /apis/v1/applications/operations/{appId}/cancel</code></p> <p>Request <pre><code>curl --location --request POST 'http://drove.local:7000/apis/v1/operations/TEST_APP/cancel' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4=' \\\n--data ''\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/application/#get-list-of-applications","title":"Get list of applications","text":"<p><code>GET /apis/v1/applications</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/applications' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"TEST_APP-1\": {\n            \"id\": \"TEST_APP-1\",\n            \"name\": \"TEST_APP\",\n            \"requiredInstances\": 0,\n            \"healthyInstances\": 0,\n            \"totalCPUs\": 0,\n            \"totalMemory\": 0,\n            \"state\": \"MONITORING\",\n            \"created\": 1719826995764,\n            \"updated\": 1719892126096\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/application/#get-info-for-an-app","title":"Get info for an app","text":"<p><code>GET /apis/v1/applications/{id}</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/applications/TEST_APP-1' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"id\": \"TEST_APP-1\",\n        \"name\": \"TEST_APP\",\n        \"requiredInstances\": 1,\n        \"healthyInstances\": 1,\n        \"totalCPUs\": 1,\n        \"totalMemory\": 128,\n        \"state\": \"RUNNING\",\n        \"created\": 1719826995764,\n        \"updated\": 1719892279019\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/application/#get-raw-json-specs","title":"Get raw JSON specs","text":"<p><code>GET /apis/v1/applications/{id}/spec</code></p> <p>Request</p> <pre><code>curl --location 'http://drove.local:7000/apis/v1/applications/TEST_APP-1/spec' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"name\": \"TEST_APP\",\n        \"version\": \"1\",\n        \"executable\": {\n            \"type\": \"DOCKER\",\n            \"url\": \"ghcr.io/appform-io/perf-test-server-httplib\",\n            \"dockerPullTimeout\": \"100 seconds\"\n        },\n        \"exposedPorts\": [\n            {\n                \"name\": \"main\",\n                \"port\": 8000,\n                \"type\": \"HTTP\"\n            }\n        ],\n        \"volumes\": [],\n        \"configs\": [\n            {\n                \"type\": \"INLINE\",\n                \"localFilename\": \"/testfiles/drove.txt\",\n                \"data\": \"\"\n            }\n        ],\n        \"type\": \"SERVICE\",\n        \"resources\": [\n            {\n                \"type\": \"CPU\",\n                \"count\": 1\n            },\n            {\n                \"type\": \"MEMORY\",\n                \"sizeInMB\": 128\n            }\n        ],\n        \"placementPolicy\": {\n            \"type\": \"ANY\"\n        },\n        \"healthcheck\": {\n            \"mode\": {\n                \"type\": \"HTTP\",\n                \"protocol\": \"HTTP\",\n                \"portName\": \"main\",\n                \"path\": \"/\",\n                \"verb\": \"GET\",\n                \"successCodes\": [\n                    200\n                ],\n                \"payload\": \"\",\n                \"connectionTimeout\": \"1 second\",\n                \"insecure\": false\n            },\n            \"timeout\": \"1 second\",\n            \"interval\": \"5 seconds\",\n            \"attempts\": 3,\n            \"initialDelay\": \"0 seconds\"\n        },\n        \"readiness\": {\n            \"mode\": {\n                \"type\": \"HTTP\",\n                \"protocol\": \"HTTP\",\n                \"portName\": \"main\",\n                \"path\": \"/\",\n                \"verb\": \"GET\",\n                \"successCodes\": [\n                    200\n                ],\n                \"payload\": \"\",\n                \"connectionTimeout\": \"1 second\",\n                \"insecure\": false\n            },\n            \"timeout\": \"1 second\",\n            \"interval\": \"3 seconds\",\n            \"attempts\": 3,\n            \"initialDelay\": \"0 seconds\"\n        },\n        \"tags\": {\n            \"superSpecialApp\": \"yes_i_am\",\n            \"say_my_name\": \"heisenberg\"\n        },\n        \"env\": {\n            \"CORES\": \"8\"\n        },\n        \"exposureSpec\": {\n            \"vhost\": \"testapp.local\",\n            \"portName\": \"main\",\n            \"mode\": \"ALL\"\n        },\n        \"preShutdown\": {\n            \"hooks\": [\n                {\n                    \"type\": \"HTTP\",\n                    \"protocol\": \"HTTP\",\n                    \"portName\": \"main\",\n                    \"path\": \"/\",\n                    \"verb\": \"GET\",\n                    \"successCodes\": [\n                        200\n                    ],\n                    \"payload\": \"\",\n                    \"connectionTimeout\": \"1 second\",\n                    \"insecure\": false\n                }\n            ],\n            \"waitBeforeKill\": \"3 seconds\"\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p> <p>Note</p> <p><code>configs</code> section data will not be returned by any api calls</p>"},{"location":"apis/application/#get-list-of-currently-active-instances","title":"Get list of currently active instances","text":"<p><code>GET /apis/v1/applications/{id}/instances</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/applications/TEST_APP-1/instances' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": [\n        {\n            \"appId\": \"TEST_APP-1\",\n            \"appName\": \"TEST_APP\",\n            \"instanceId\": \"AI-58eb1111-8c2c-4ea2-a159-8fc68010a146\",\n            \"executorId\": \"a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d\",\n            \"localInfo\": {\n                \"hostname\": \"ppessdev\",\n                \"ports\": {\n                    \"main\": {\n                        \"containerPort\": 8000,\n                        \"hostPort\": 33857,\n                        \"portType\": \"HTTP\"\n                    }\n                }\n            },\n            \"resources\": [\n                {\n                    \"type\": \"CPU\",\n                    \"cores\": {\n                        \"0\": [\n                            2\n                        ]\n                    }\n                },\n                {\n                    \"type\": \"MEMORY\",\n                    \"memoryInMB\": {\n                        \"0\": 128\n                    }\n                }\n            ],\n            \"state\": \"HEALTHY\",\n            \"metadata\": {},\n            \"errorMessage\": \"\",\n            \"created\": 1719892354194,\n            \"updated\": 1719893180105\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/application/#get-list-of-old-instances","title":"Get list of old instances","text":"<p><code>GET /apis/v1/applications/{id}/instances/old</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/applications/TEST_APP-1/instances/old' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": [\n        {\n            \"appId\": \"TEST_APP-1\",\n            \"appName\": \"TEST_APP\",\n            \"instanceId\": \"AI-869e34ed-ebf3-4908-bf48-719475ca5640\",\n            \"executorId\": \"a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d\",\n            \"resources\": [\n                {\n                    \"type\": \"CPU\",\n                    \"cores\": {\n                        \"0\": [\n                            2\n                        ]\n                    }\n                },\n                {\n                    \"type\": \"MEMORY\",\n                    \"memoryInMB\": {\n                        \"0\": 128\n                    }\n                }\n            ],\n            \"state\": \"STOPPED\",\n            \"metadata\": {},\n            \"errorMessage\": \"Error while pulling image ghcr.io/appform-io/perf-test-server-httplib: Status 500: {\\\"message\\\":\\\"Get \\\\\\\"https://ghcr.io/v2/\\\\\\\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\\\"}\\n\",\n            \"created\": 1719892279039,\n            \"updated\": 1719892354099\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/application/#get-info-for-an-instance","title":"Get info for an instance","text":"<p><code>GET /apis/v1/applications/{appId}/instances/{instanceId}</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/applications/TEST_APP-1/instances/AI-58eb1111-8c2c-4ea2-a159-8fc68010a146' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"appId\": \"TEST_APP-1\",\n        \"appName\": \"TEST_APP\",\n        \"instanceId\": \"AI-58eb1111-8c2c-4ea2-a159-8fc68010a146\",\n        \"executorId\": \"a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d\",\n        \"localInfo\": {\n            \"hostname\": \"ppessdev\",\n            \"ports\": {\n                \"main\": {\n                    \"containerPort\": 8000,\n                    \"hostPort\": 33857,\n                    \"portType\": \"HTTP\"\n                }\n            }\n        },\n        \"resources\": [\n            {\n                \"type\": \"CPU\",\n                \"cores\": {\n                    \"0\": [\n                        2\n                    ]\n                }\n            },\n            {\n                \"type\": \"MEMORY\",\n                \"memoryInMB\": {\n                    \"0\": 128\n                }\n            }\n        ],\n        \"state\": \"HEALTHY\",\n        \"metadata\": {},\n        \"errorMessage\": \"\",\n        \"created\": 1719892354194,\n        \"updated\": 1719893440105\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/application/#application-endpoints","title":"Application Endpoints","text":"<p><code>GET /apis/v1/endpoints</code></p> <p>Info</p> <p>This API provides up-to-date information about the host and port information about application instances running on the cluster. This information can be used for Service Discovery systems to keep their information in sync with changes in the topology of applications running on the cluster.</p> <p>Tip</p> <p>Any <code>tag</code> specified in the application specification is also exposed on endpoint. This can be used to implement complicated routing logic if needed in the NGinx template on Drove Gateway.</p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/endpoints' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": [\n        {\n            \"appId\": \"TEST_APP-1\",\n            \"vhost\": \"testapp.local\",\n            \"tags\": {\n                \"superSpecialApp\": \"yes_i_am\",\n                \"say_my_name\": \"heisenberg\"\n            },\n            \"hosts\": [\n                {\n                    \"host\": \"ppessdev\",\n                    \"port\": 44315,\n                    \"portType\": \"HTTP\"\n                }\n            ]\n        },\n        {\n            \"appId\": \"TEST_APP-2\",\n            \"vhost\": \"testapp.local\",\n            \"tags\": {\n                \"superSpecialApp\": \"yes_i_am\",\n                \"say_my_name\": \"heisenberg\"\n            },\n            \"hosts\": [\n                {\n                    \"host\": \"ppessdev\",\n                    \"port\": 46623,\n                    \"portType\": \"HTTP\"\n                }\n            ]\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/cluster/","title":"Cluster Management","text":""},{"location":"apis/cluster/#ping-api","title":"Ping API","text":"<p><code>GET /apis/v1/ping</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/ping' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": \"pong\",\n    \"message\": \"success\"\n}\n</code></pre></p> <p>Tip</p> <p>Use this api call to determine the leader in a cluster. This api will return a HTTP 200 only for the leader controller. All other controllers in the cluster will return 4xx for this api call.</p>"},{"location":"apis/cluster/#cluster-management_1","title":"Cluster Management","text":""},{"location":"apis/cluster/#get-current-cluster-state","title":"Get current cluster state","text":"<p><code>GET /apis/v1/cluster</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/cluster' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"leader\": \"ppessdev:4000\",\n        \"state\": \"NORMAL\",\n        \"numExecutors\": 1,\n        \"numApplications\": 1,\n        \"numActiveApplications\": 1,\n        \"freeCores\": 9,\n        \"usedCores\": 1,\n        \"totalCores\": 10,\n        \"freeMemory\": 18898,\n        \"usedMemory\": 128,\n        \"totalMemory\": 19026\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/cluster/#set-maintenance-mode-on-cluster","title":"Set maintenance mode on cluster","text":"<p><code>POST /apis/v1/cluster/maintenance/set</code></p> <p>Request <pre><code>curl --location --request POST 'http://drove.local:7000/apis/v1/cluster/maintenance/set' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4=' \\\n--data ''\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"state\": \"MAINTENANCE\",\n        \"updated\": 1719897526772\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/cluster/#remove-maintenance-mode-from-cluster","title":"Remove maintenance mode from cluster","text":"<p><code>POST /apis/v1/cluster/maintenance/unset</code></p> <p>Request <pre><code>curl --location --request POST 'http://drove.local:7000/apis/v1/cluster/maintenance/unset' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4=' \\\n--data ''\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"state\": \"NORMAL\",\n        \"updated\": 1719897573226\n    },\n    \"message\": \"success\"\n}\n</code></pre></p> <p>Warning</p> <p>Cluster will remain in maintenance mode for some time (about 2 minutes) internally even after maintenance mode is removed.</p>"},{"location":"apis/cluster/#executor-management","title":"Executor Management","text":""},{"location":"apis/cluster/#get-list-of-executors","title":"Get list of executors","text":"<p><code>GET /apis/v1/cluster/executors</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/cluster/executors' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": [\n        {\n            \"executorId\": \"a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d\",\n            \"hostname\": \"ppessdev\",\n            \"port\": 3000,\n            \"transportType\": \"HTTP\",\n            \"freeCores\": 9,\n            \"usedCores\": 1,\n            \"freeMemory\": 18898,\n            \"usedMemory\": 128,\n            \"tags\": [\n                \"ppessdev\"\n            ],\n            \"state\": \"ACTIVE\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/cluster/#get-detailed-info-for-one-executor","title":"Get detailed info for one executor","text":"<p><code>GET /apis/v1/cluster/executors/{id}</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/cluster/executors/a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"type\": \"EXECUTOR\",\n        \"hostname\": \"ppessdev\",\n        \"port\": 3000,\n        \"transportType\": \"HTTP\",\n        \"updated\": 1719897100104,\n        \"state\": {\n            \"executorId\": \"a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d\",\n            \"cpus\": {\n                \"type\": \"CPU\",\n                \"freeCores\": {\n                    \"0\": [\n                        3,\n                        4,\n                        5,\n                        6,\n                        7,\n                        8,\n                        9,\n                        10,\n                        11\n                    ]\n                },\n                \"usedCores\": {\n                    \"0\": [\n                        2\n                    ]\n                }\n            },\n            \"memory\": {\n                \"type\": \"MEMORY\",\n                \"freeMemory\": {\n                    \"0\": 18898\n                },\n                \"usedMemory\": {\n                    \"0\": 128\n                }\n            }\n        },\n        \"instances\": [\n            {\n                \"appId\": \"TEST_APP-1\",\n                \"appName\": \"TEST_APP\",\n                \"instanceId\": \"AI-58eb1111-8c2c-4ea2-a159-8fc68010a146\",\n                \"executorId\": \"a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d\",\n                \"localInfo\": {\n                    \"hostname\": \"ppessdev\",\n                    \"ports\": {\n                        \"main\": {\n                            \"containerPort\": 8000,\n                            \"hostPort\": 33857,\n                            \"portType\": \"HTTP\"\n                        }\n                    }\n                },\n                \"resources\": [\n                    {\n                        \"type\": \"CPU\",\n                        \"cores\": {\n                            \"0\": [\n                                2\n                            ]\n                        }\n                    },\n                    {\n                        \"type\": \"MEMORY\",\n                        \"memoryInMB\": {\n                            \"0\": 128\n                        }\n                    }\n                ],\n                \"state\": \"HEALTHY\",\n                \"metadata\": {},\n                \"errorMessage\": \"\",\n                \"created\": 1719892354194,\n                \"updated\": 1719897100104\n            }\n        ],\n        \"tasks\": [],\n        \"tags\": [\n            \"ppessdev\"\n        ],\n        \"blacklisted\": false\n    },\n    \"message\": \"success\"\n}\n</code></pre>"},{"location":"apis/cluster/#take-executor-out-of-rotation","title":"Take executor out of rotation","text":"<p><code>POST /apis/v1/cluster/executors/blacklist</code></p> <p>Request <pre><code>curl --location --request POST 'http://drove.local:7000/apis/v1/cluster/executors/blacklist?id=a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4=' \\\n--data ''\n</code></pre></p> <p>Note</p> <p>Unlike other POST apis, the executors to be blacklisted are passed as query parameter <code>id</code>. To blacklist multiple executors, pass <code>.../blacklist?id=&lt;id1&gt;&amp;id=&lt;id2&gt;...</code></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"successful\": [\n            \"a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d\"\n        ],\n        \"failed\": []\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/cluster/#bring-executor-back-into-rotation","title":"Bring executor back into rotation","text":"<p><code>POST /apis/v1/cluster/executors/unblacklist</code></p> <p>Request <pre><code>curl --location --request POST 'http://drove.local:7000/apis/v1/cluster/executors/unblacklist?id=a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4=' \\\n--data ''\n</code></pre></p> <p>Note</p> <p>Unlike other POST apis, the executors to be un-blacklisted are passed as query parameter <code>id</code>. To un-blacklist multiple executors, pass <code>.../unblacklist?id=&lt;id1&gt;&amp;id=&lt;id2&gt;...</code></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"successful\": [\n            \"a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d\"\n        ],\n        \"failed\": []\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/cluster/#drove-cluster-events","title":"Drove Cluster Events","text":"<p>The following APIs can be used to monitor events on Drove. If the data needs to be consumed, the <code>/latest</code> API should be used. For simply knowing if an event of a certain type has occurred or not, the <code>/summary</code> is sufficient.</p>"},{"location":"apis/cluster/#event-list","title":"Event List","text":"<p><code>GET /apis/v1/cluster/events/latest</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/cluster/events/latest?size=1024&amp;lastSyncTime=0' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"events\": [\n            {\n                \"metadata\": {\n                    \"CURRENT_INSTANCES\": 0,\n                    \"APP_ID\": \"TEST_APP-1\",\n                    \"PLACEMENT_POLICY\": \"ANY\",\n                    \"APP_VERSION\": \"1\",\n                    \"CPU_COUNT\": 1,\n                    \"CURRENT_STATE\": \"RUNNING\",\n                    \"PORTS\": \"main:8000:http\",\n                    \"MEMORY\": 128,\n                    \"EXECUTABLE\": \"ghcr.io/appform-io/perf-test-server-httplib\",\n                    \"VHOST\": \"testapp.local\",\n                    \"APP_NAME\": \"TEST_APP\"\n                },\n                \"type\": \"APP_STATE_CHANGE\",\n                \"id\": \"a2b7d673-2bc2-4084-8415-d8d37cafa63d\",\n                \"time\": 1719977632050\n            },\n            {\n                \"metadata\": {\n                    \"APP_NAME\": \"TEST_APP\",\n                    \"APP_ID\": \"TEST_APP-1\",\n                    \"PORTS\": \"main:44315:http\",\n                    \"EXECUTOR_ID\": \"a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d\",\n                    \"EXECUTOR_HOST\": \"ppessdev\",\n                    \"CREATED\": 1719977629042,\n                    \"INSTANCE_ID\": \"AI-5efbb94f-835c-4c62-a073-a68437e60339\",\n                    \"CURRENT_STATE\": \"HEALTHY\"\n                },\n                \"type\": \"INSTANCE_STATE_CHANGE\",\n                \"id\": \"55d5876f-94ac-4c5d-a580-9c3b296add46\",\n                \"time\": 1719977631534\n            }\n        ],\n        \"lastSyncTime\": 1719977632050//(1)!\n    },\n    \"message\": \"success\"\n}\n</code></pre></p> <ol> <li>Pass this as the parameter <code>lastSyncTime</code> in the next call to <code>events</code> api to receive latest events.</li> </ol> Query Parameter Validation Description lastSyncTime +ve long range Time when the last sync call happened on the server. Defaults to 0 (initial sync). size 1-1024 Number of latest events to return. Defaults to 1024. We recommend leaving this as is."},{"location":"apis/cluster/#event-summary","title":"Event Summary","text":"<p><code>GET /apis/v1/cluster/events/summary</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/cluster/events/summary?lastSyncTime=0' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre> Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"eventsCount\": {\n            \"INSTANCE_STATE_CHANGE\": 8,\n            \"APP_STATE_CHANGE\": 17,\n            \"EXECUTOR_BLACKLISTED\": 1,\n            \"EXECUTOR_UN_BLACKLISTED\": 1\n        },\n        \"lastSyncTime\": 1719977632050//(1)!\n    },\n    \"message\": \"success\"\n}\n</code></pre></p> <ol> <li>Pass this as the parameter <code>lastSyncTime</code> in the next call to <code>events</code> api to receive latest events.</li> </ol>"},{"location":"apis/cluster/#continuous-monitoring-for-events","title":"Continuous monitoring for events","text":"<p>This is applicable for both the APIs listed above</p> <ul> <li>In the first call to events api, pass <code>lastSyncTime</code> as zero.</li> <li>In the response there will be a field <code>lastSyncTime</code></li> <li>Pass the last received <code>lastSyncTime</code> as the <code>lastSyncTime</code> param in the next call</li> <li>This api is cheap enough, you should plan to make calls to it every few seconds</li> </ul> <p>Info</p> <p>Model for the events can be found here.</p> <p>Tip</p> <p>Java programs should definitely look at using the event listener library  to listen to cluster events</p>"},{"location":"apis/logs/","title":"Log Related APIs","text":""},{"location":"apis/logs/#get-list-if-log-files","title":"Get list if log files","text":"<p>Application <code>GET /apis/v1/logfiles/applications/{appId}/{instanceId}/list</code></p> <p>Task <code>GET /apis/v1/logfiles/tasks/{sourceAppName}/{taskId}/list</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/logfiles/applications/TEST_APP-1/AI-5efbb94f-835c-4c62-a073-a68437e60339/list' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"files\": [\n        \"output.log-2024-07-04\",\n        \"output.log-2024-07-03\",\n        \"output.log\"\n    ]\n}\n</code></pre></p>"},{"location":"apis/logs/#download-log-files","title":"Download Log Files","text":"<p>Application <code>GET /apis/v1/logfiles/applications/{appId}/{instanceId}/download/{fileName}</code></p> <p>Task <code>GET /apis/v1/logfiles/tasks/{sourceAppName}/{taskId}/download/{fileName}</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/logfiles/applications/TEST_APP-1/AI-5efbb94f-835c-4c62-a073-a68437e60339/download/output.log' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <p>Note</p> <p>The <code>Content-Disposition</code> header is set properly to the actual filename. For the above example it would be set to <code>attachment; filename=output.log</code>.</p>"},{"location":"apis/logs/#read-chunks-from-log","title":"Read chunks from log","text":"<p>Application <code>GET /apis/v1/logfiles/applications/{appId}/{instanceId}/read/{fileName}</code></p> <p>Task <code>GET /apis/v1/logfiles/tasks/{sourceAppName}/{taskId}/read/{fileName}</code></p> Query Parameter Validation Description offset Default -1, should be positive number The offset of the file to read from. length Should be a positive number Number of bytes to read. <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/logfiles/applications/TEST_APP-1/AI-5efbb94f-835c-4c62-a073-a68437e60339/read/output.log' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"data\": \"\", //(1)!\n    \"offset\": 43318 //(2)!\n}\n</code></pre></p> <ol> <li>Will contain raw data or empty string (in case of first call)</li> <li>Offset to be passed in the next call</li> </ol>"},{"location":"apis/logs/#how-to-tail-logs","title":"How to tail logs","text":"<ol> <li>Have a fixed buffer size in ming 1024/4096 etc</li> <li>Make a call to <code>/read</code> api with offset=<code>-1</code>, length = <code>buffer size</code></li> <li>The call will return no data, but will have a valid offset</li> <li>Pass this offset in the next call, data will be returned if available (or empty). The response will also return the offset to pass in the .ext call.</li> <li>The <code>data</code> returned might be empty or less than <code>length</code> depending on availability.</li> <li>Keep repeating (4) to keep tailing log</li> </ol> <p>Warning</p> <ul> <li>Offset = 0 means start of the file</li> <li>First call must be -1 for <code>tail</code> type functionality</li> </ul>"},{"location":"apis/task/","title":"Task Management","text":""},{"location":"apis/task/#issue-task-operation","title":"Issue task operation","text":"<p><code>POST /apis/v1/tasks/operations</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/tasks/operations' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4=' \\\n--data '{\n    \"type\": \"KILL\",\n    \"sourceAppName\" : \"TEST_APP\",\n    \"taskId\" : \"T0012\",\n    \"opSpec\": {\n        \"timeout\": \"5m\",\n        \"parallelism\": 1,\n        \"failureStrategy\": \"STOP\"\n    }\n}'\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"taskId\": \"T0012\"\n    },\n    \"message\": \"success\"\n}\n</code></pre></p> <p>Tip</p> <p>Relevant payloads for task commands can be found in task operations section.</p>"},{"location":"apis/task/#search-for-task","title":"Search for task","text":"<p><code>POST /apis/v1/tasks/search</code></p>"},{"location":"apis/task/#list-all-tasks","title":"List all tasks","text":"<p><code>GET /apis/v1/tasks</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/tasks' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": [\n        {\n            \"sourceAppName\": \"TEST_APP\",\n            \"taskId\": \"T0013\",\n            \"instanceId\": \"TI-c2140806-2bb5-4ed3-9bb9-0c0c5fd0d8d6\",\n            \"executorId\": \"a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d\",\n            \"hostname\": \"ppessdev\",\n            \"executable\": {\n                \"type\": \"DOCKER\",\n                \"url\": \"ghcr.io/appform-io/test-task\",\n                \"dockerPullTimeout\": \"100 seconds\"\n            },\n            \"resources\": [\n                {\n                    \"type\": \"CPU\",\n                    \"cores\": {\n                        \"0\": [\n                            2\n                        ]\n                    }\n                },\n                {\n                    \"type\": \"MEMORY\",\n                    \"memoryInMB\": {\n                        \"0\": 512\n                    }\n                }\n            ],\n            \"volumes\": [],\n            \"env\": {\n                \"ITERATIONS\": \"10\"\n            },\n            \"state\": \"RUNNING\",\n            \"metadata\": {},\n            \"errorMessage\": \"\",\n            \"created\": 1719827035480,\n            \"updated\": 1719827038414\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"apis/task/#get-task-instance-details","title":"Get Task Instance Details","text":"<p><code>GET /apis/v1/tasks/{sourceAppName}/instances/{taskId}</code></p> <p>Request <pre><code>curl --location 'http://drove.local:7000/apis/v1/tasks/TEST_APP/instances/T0012' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4='\n</code></pre></p> <p>Response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"sourceAppName\": \"TEST_APP\",\n        \"taskId\": \"T0012\",\n        \"instanceId\": \"TI-6cf36f5c-6480-4ed5-9e2d-f79d9648529a\",\n        \"executorId\": \"a45442a1-d4d0-3479-ab9e-3ed0aa5f7d2d\",\n        \"hostname\": \"ppessdev\",\n        \"executable\": {\n            \"type\": \"DOCKER\",\n            \"url\": \"ghcr.io/appform-io/test-task\",\n            \"dockerPullTimeout\": \"100 seconds\"\n        },\n        \"resources\": [\n            {\n                \"type\": \"CPU\",\n                \"cores\": {\n                    \"0\": [\n                        3\n                    ]\n                }\n            },\n            {\n                \"type\": \"MEMORY\",\n                \"memoryInMB\": {\n                    \"0\": 512\n                }\n            }\n        ],\n        \"volumes\": [],\n        \"env\": {\n            \"ITERATIONS\": \"10\"\n        },\n        \"state\": \"STOPPED\",\n        \"metadata\": {},\n        \"taskResult\": {\n            \"status\": \"SUCCESSFUL\",\n            \"exitCode\": 0\n        },\n        \"errorMessage\": \"\",\n        \"created\": 1719823470267,\n        \"updated\": 1719823483836\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"applications/","title":"Introduction","text":"<p>An application is a virtual representation of a running service in the system.</p> <p>Running containers for an application are called application instances.</p> <p>An application specification contains the following details about the application:</p> <ul> <li>Name - Name of the application</li> <li>Version - Version of this specification</li> <li>Executable - The container to deploy on the cluster</li> <li>Ports - Ports to be exposed from the container</li> <li>Resources - CPU and Memory required for the container</li> <li>Placement Policy - How containers are to be placed in the cluster</li> <li>Healthchecks - Healthcheck details</li> <li>Readiness Checks - Readiness checks to pass before container is considered to be healthy</li> <li>Pre Shutdown Hooks - Pre shutdown hooks to run on container before it is killed</li> <li>Environment Variables - Environment variables and values</li> <li>Exposure Information - Virtual host information</li> <li>Volumes - Volumes to be mounted into the container</li> <li>Configs - Configs/files to be mounted into the container</li> <li>Logging details - Logging spec (for example rsyslog server)</li> <li>Tags - A map of strings for additional metadata</li> </ul> <p>Info</p> <p>Once a spec is registered to the cluster, it can not be changed</p>"},{"location":"applications/#application-id","title":"Application ID","text":"<p>Once an application is created on the cluster, an Application id is generated. The format of this id currently is: <code>{name}-{version}</code>. All further operations to be done on the application will need to refer to it by this ID.</p>"},{"location":"applications/#application-states-and-operations","title":"Application States and Operations","text":"<p>An application on a Drove cluster follows a fixed lifecycle modelled as a state machine. State transitions are triggered by operations. Operations can be issued externally using API calls or may be generated internally by the application monitoring system.</p>"},{"location":"applications/#states","title":"States","text":"<p>Applications on a Drove cluster can be one of the following states:</p> <ul> <li>INIT - This is an intermediate state during which the application is being initialized and  the spec is being validated. This is the origination state of the application.</li> <li>MONITORING - A stable state in which application is created or suspended and does not have any running instances</li> <li>RUNNING - A stable state in which application has the expected non-zero number of healthy application instances running on the cluster</li> <li>OUTAGE_DETECTED - An intermediate state when Drove has detected that the current number of application instances is not matching the expected number of instances.</li> <li>SCALING_REQUESTED - An intermediate state that signifies that application instances are being spun up or shut down to get the number of running instances to match the expected instances.</li> <li>STOP_INSTANCES_REQUESTED - An intermediate state that signifies that specific instances of the application are being killed as requested by the user/system.</li> <li>REPLACE_INSTANCES_REQUESTED - An _intermediate state _that signifies that instances of the application are being replaced with newer instances as requested by the user. This signifies that the app is effectively being restarted.</li> <li>DESTROY_REQUESTED - An intermediate state that signifies that the user has requested to destroy the application and remove it from the cluster.</li> <li>DESTROYED - An intermediate state that signifies that the app has been destroyed and metadata cleanup is underway. This is the terminal state of an application.</li> </ul>"},{"location":"applications/#operations","title":"Operations","text":"<p>The following application operations are recognized by Drove:</p> <ul> <li>CREATE - Create an application. Take the Application Specification. Fails if an app with the same application id (name + version) already exists on the cluster</li> <li>DESTROY - Destroy an application. Takes app id as parameter. Deletes all metadata about the application from the cluster. Allowed only if the application is in Monitoring state (i.e. has zero running instances).</li> <li>START_INSTANCES - Create new application instances. Takes the app id as well as the number of new instances to deploy. Allowed only if the application is in Monitoring or Running state.</li> <li>STOP_INSTANCES - Stop running application instances. Takes the app id, list of instance ids to be stopped as well as flag to denote if replacement instances are to be started by Drove or not. Allowed only if the application is in Monitoring or Running state.</li> <li>SCALE - Scale the application up and down to the specified number of instances. Drove will internally calculate whether to spin new containers up or spin old containers down as needed. Allowed if the app is in Monitoring or Running state. It is better to use either START or STOP instances command above to be more explicit in behavior. The SCALE operation is mostly for internal use by Drove, but can be issued externally as well.</li> <li>REPLACE_INSTANCES - Replace application instances with newer ones. Can be used to do rolling restarts on the cluster. Specific instances can be targeted as well by passing an optional list of instance ids to be replaced. Allowed only when the application is in Running state.</li> <li>SUSPEND - A shortcut to set expected instances for an application to zero. This will get translated into a SCALE operation and any running instances will be gracefully shut down. Allowed only when the application is in running state.</li> <li>RECOVER - Internal command used to restore application state on controller failover.</li> </ul> <p>Tip</p> <p>All operations can take an optional Cluster Operation Spec which can be used to control the timeout and parallelism of tasks generated by the operation.</p>"},{"location":"applications/#application-state-machine","title":"Application State Machine","text":"<p>The following state machine signifies the states and transitions as affected by cluster state and operations issued.</p> <p></p>"},{"location":"applications/instances/","title":"Application Instances","text":"<p>Application instances are running containers for an application. The state machine for instances are managed in a decentralised manner on the cluster nodes locally and not by the controllers. This includes running health checks, readiness checks and shutdown hooks on the container, container loss detection and container state recovery on executor service restart.</p> <p>Regular updates about the instance state are provided by executors to the controllers and are used to keep the application state up-to-date or trigger application operations to bring the applications to stable states.</p>"},{"location":"applications/instances/#application-instance-states","title":"Application Instance States","text":"<p>An application instance can be in one of the following states at one point in time:</p> <ul> <li>PENDING - Container state machine start has been triggered.</li> <li>PROVISIONING - Docker image is being downloaded</li> <li>PROVISIONING_FAILED - Docker image download failed</li> <li>STARTING - Docker run is being executed</li> <li>START_FAILED - Docker run failed</li> <li>UNREADY - Docker started, readiness check not yet started.</li> <li>READINESS_CHECK_FAILED - Readiness check was run and has failed terminally</li> <li>READY - Readiness checks have passed</li> <li>HEALTHY - Health check has passed. Container is running properly and passing regular health checks</li> <li>UNHEALTHY - Regular health check has failed. Container will stop.</li> <li>STOPPING - Shutdown hooks are being called and docker kill be be issued</li> <li>DEPROVISIONING - Docker image is being cleaned up</li> <li>STOPPED - Docker stop has completed</li> <li>LOST - Container has exited unexpectedly while executor service was down</li> <li>UNKNOWN - All running containers are in this state when executor service is getting restarted and before startup recovery has kicked in</li> </ul>"},{"location":"applications/instances/#application-instance-state-machine","title":"Application Instance State Machine","text":"<p>Instance state machine transitions might be triggered on receipt of commands issued by the controller or due to internal changes in the container (might have died or started failing health checks) as well as external factors like executor service restarts.</p> <p></p> <p>Note</p> <p>No operations are allowed to be performed on application instances directly through the executor</p>"},{"location":"applications/operations/","title":"Application Operations","text":"<p>This page discusses operations relevant to Application management. Please go over the Application State Machine and Application Instance State Machine to understand the different states an application (and it's instances) can be in and how operations applied move an application from one state to another.</p> <p>Note</p> <p>Please go through Cluster Op Spec to understand the operation parameters being sent.</p> <p>Note</p> <p>Only one operation can be active on a particular <code>{appName,version}</code> combination.</p> <p>Warning</p> <p>Only the leader controller will accept and process operations. To avoid confusion, use the controller endpoint exposed by Drove Gateway to issue commands.</p>"},{"location":"applications/operations/#how-to-initiate-an-operation","title":"How to initiate an operation","text":"<p>Tip</p> <p>Use the Drove CLI to perform all manual operations.</p> <p>All operations for application lifecycle management need to be issued via a POST HTTP call to the leader controller endpoint on the path <code>/apis/v1/applications/operations</code>. API will return HTTP OK/200 and relevant json response as payload.</p> <p>Sample api call:</p> <pre><code>curl --location 'http://drove.local:7000/apis/v1/applications/operations' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4=' \\\n--data '{\n    \"type\": \"START_INSTANCES\",\n    \"appId\": \"TEST_APP-3\",\n    \"instances\": 1,\n    \"opSpec\": {\n        \"timeout\": \"5m\",\n        \"parallelism\": 32,\n        \"failureStrategy\": \"STOP\"\n    }\n}'\n</code></pre> <p>Note</p> <p>In the above examples, <code>http://drove.local:7000</code> is the endpoint of the leader. <code>TEST_APP-3</code> is the Application ID. Authorization is basic auth.</p>"},{"location":"applications/operations/#how-to-cancel-an-operation","title":"How to cancel an operation","text":"<p>Operations can be requested to be cancelled asynchronously. A POST call needs to be made to leader controller endpoint on the api <code>/apis/v1/operations/{applicationId}/cancel</code> (1) to achieve this.</p> <ol> <li><code>applicationId</code> is the Application ID for the application</li> </ol> <pre><code>curl --location --request POST 'http://drove.local:7000/apis/v1/operations/TEST_APP-3/cancel' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4=' \\\n--data ''\n</code></pre> <p>Warning</p> <p>Operation cancellation is not instantaneous. Cancellation will be affected only after current execution of the active operation is complete.</p>"},{"location":"applications/operations/#create-an-application","title":"Create an application","text":"<p>Before deploying containers on the cluster, an application needs to be created.</p> <p>Preconditions:</p> <ul> <li>App should not exist in the cluster</li> </ul> <p>State Transition: </p> <ul> <li>none \u2192 <code>MONITORING</code></li> </ul> <p>To create an application, an Application Spec needs to be created first. </p> <p>Once ready, CLI command needs to be issued or the following payload needs to be sent:</p> Drove CLIJSON <pre><code>drove -c local apps create sample/test_app.json\n</code></pre> <p>Sample Request Payload <pre><code>{\n    \"type\": \"CREATE\",\n    \"spec\": {...}, //(1)!\n    \"opSpec\": { //(2)!\n        \"timeout\": \"5m\",\n        \"parallelism\": 1,\n        \"failureStrategy\": \"STOP\"\n    }\n}\n</code></pre></p> <ol> <li>Spec as mentioned in Application Specification</li> <li>Operation spec as mentioned in Cluster Op Spec</li> </ol> <p>Sample response <pre><code>{\n    \"data\" : {\n        \"appId\" : \"TEST_APP-1\"\n    },\n    \"message\" : \"success\",\n    \"status\" : \"SUCCESS\"\n}\n</code></pre></p>"},{"location":"applications/operations/#starting-new-instances-of-an-application","title":"Starting new instances of an application","text":"<p>New instances can be started by issuing the  <code>START_INSTANCES</code> command.</p> <p>Preconditions - Application must be in one of the following states: <code>MONITORING</code>, <code>RUNNING</code></p> <p>State Transition:</p> <ul> <li>{<code>RUNNING</code>, <code>MONITORING</code>} \u2192 <code>RUNNING</code></li> </ul> <p>The following command/payload will start <code>2</code> new instances of the application.</p> Drove CLIJSON <pre><code>drove -c local apps deploy TEST_APP-1 2\n</code></pre> <p>Sample Request Payload <pre><code>{\n    \"type\": \"START_INSTANCES\",\n    \"appId\": \"TEST_APP-1\",//(1)!\n    \"instances\": 2,//(2)!\n    \"opSpec\": {//(3)!\n        \"timeout\": \"5m\",\n        \"parallelism\": 32,\n        \"failureStrategy\": \"STOP\"\n    }\n}\n</code></pre></p> <ol> <li>Application ID</li> <li>Number of instances to be started</li> <li>Operation spec as mentioned in Cluster Op Spec</li> </ol> <p>Sample response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"appId\": \"TEST_APP-1\"\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"applications/operations/#suspending-an-application","title":"Suspending an application","text":"<p>All instances of an application can be shut down by issuing the  <code>SUSPEND</code> command.</p> <p>Preconditions - Application must be in one of the following states: <code>MONITORING</code>, <code>RUNNING</code></p> <p>State Transition:</p> <ul> <li>{<code>RUNNING</code>, <code>MONITORING</code>} \u2192 <code>MONITORING</code></li> </ul> <p>The following command/payload will suspend all instances of the application.</p> Drove CLIJSON <pre><code>drove -c local apps suspend TEST_APP-1\n</code></pre> <p>Sample Request Payload <pre><code>{\n    \"type\": \"SUSPEND\",\n    \"appId\": \"TEST_APP-1\",//(1)!\n    \"opSpec\": {//(2)!\n        \"timeout\": \"5m\",\n        \"parallelism\": 32,\n        \"failureStrategy\": \"STOP\"\n    }\n}\n</code></pre></p> <ol> <li>Application ID</li> <li>Operation spec as mentioned in Cluster Op Spec</li> </ol> <p>Sample response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"appId\": \"TEST_APP-1\"\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"applications/operations/#scaling-the-application-up-or-down","title":"Scaling the application up or down","text":"<p>Scaling the application to required number of containers can be achieved using the <code>SCALE</code> command. Application can be either scaled up or down using this command.</p> <p>Preconditions - Application must be in one of the following states: <code>MONITORING</code>, <code>RUNNING</code></p> <p>State Transition:</p> <ul> <li>{<code>RUNNING</code>, <code>MONITORING</code>} \u2192 <code>MONITORING</code> if <code>requiredInstances</code> is set to 0</li> <li>{<code>RUNNING</code>, <code>MONITORING</code>} \u2192 <code>RUNNING</code> if <code>requiredInstances</code> is non 0</li> </ul> Drove CLIJSON <pre><code>drove -c local apps scale TEST_APP-1 2\n</code></pre> <p>Sample Request Payload <pre><code>{\n    \"type\": \"SCALE\",\n    \"appId\": \"TEST_APP-1\", //(3)!\n    \"requiredInstances\": 2, //(1)!\n    \"opSpec\": { //(2)!\n        \"timeout\": \"1m\",\n        \"parallelism\": 20,\n        \"failureStrategy\": \"STOP\"\n    }\n}\n</code></pre></p> <ol> <li>Absolute number of instances to be maintained on the cluster for the application</li> <li>Operation spec as mentioned in Cluster Op Spec</li> <li>Application ID</li> </ol> <p>Sample response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"appId\": \"TEST_APP-1\"\n    },\n    \"message\": \"success\"\n}\n</code></pre></p> <p>Note</p> <p>During scale down, older instances are stopped first</p> <p>Tip</p> <p>If implementing automation on top of Drove APIs, just use the <code>SCALE</code> command to scale up or down instead of using <code>START_INSTANCES</code> or <code>SUSPEND</code> separately.</p>"},{"location":"applications/operations/#restarting-an-application","title":"Restarting an application","text":"<p>Application can be restarted by issuing the <code>REPLACE_INSTANCES</code> operation. In this case, first <code>clusterOpSpec.parallelism</code> number of containers are spun up first and then an equivalent number of them are spun down. This ensures that cluster maintains enough capacity is maintained in the cluster to handle incoming traffic as the restart is underway. </p> <p>Warning</p> <p>If the cluster does not have sufficient capacity to spin up new containers, this operation will get stuck. So adjust your parallelism accordingly.</p> <p>Preconditions - Application must be in <code>RUNNING</code> state.</p> <p>State Transition:</p> <ul> <li><code>RUNNING</code> \u2192 <code>REPLACE_INSTANCES_REQUESTED</code> \u2192 <code>RUNNING</code></li> </ul> Drove CLIJSON <pre><code>drove -c local apps restart TEST_APP-1\n</code></pre> <p>Sample Request Payload <pre><code>{\n    \"type\": \"REPLACE_INSTANCES\",\n    \"appId\": \"TEST_APP-1\", //(1)!\n    \"instanceIds\": [], //(2)!\n    \"opSpec\": { //(3)!\n        \"timeout\": \"1m\",\n        \"parallelism\": 20,\n        \"failureStrategy\": \"STOP\"\n    }\n}\n</code></pre></p> <ol> <li>Application ID</li> <li>Instances that need to be restarted. This is optional. If nothing is passed, all instances will be replaced.</li> <li>Operation spec as mentioned in Cluster Op Spec</li> </ol> <p>Sample response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"appId\": \"TEST_APP-1\"\n    },\n    \"message\": \"success\"\n}\n</code></pre></p> <p>Tip</p> <p>To replace specific instances, pass their application instance ids (starts with <code>AI-...</code>) in the <code>instanceIds</code> parameter in the JSON payload.</p>"},{"location":"applications/operations/#stop-or-replace-specific-instances-of-an-application","title":"Stop or replace specific instances of an application","text":"<p>Application instances can be killed by issuing the <code>STOP_INSTANCES</code> operation. Default behaviour of Drove is to replace killed instances by new instances. Such new instances are always spun up before the specified(old) instances are stopped. If <code>skipRespawn</code> parameter is set to true, the application instance is killed but no new instances are spun up to replace it.</p> <p>Warning</p> <p>If the cluster does not have sufficient capacity to spin up new containers, and <code>skipRespawn</code> is not set or set to <code>false</code>, this operation will get stuck.</p> <p>Preconditions - Application must be in <code>RUNNING</code> state.</p> <p>State Transition:</p> <ul> <li><code>RUNNING</code> \u2192 <code>STOP_INSTANCES_REQUESTED</code> \u2192 <code>RUNNING</code> if final number of instances is non zero</li> <li><code>RUNNING</code> \u2192 <code>STOP_INSTANCES_REQUESTED</code> \u2192 <code>MONITORING</code> if final number of instances is zero</li> </ul> Drove CLIJSON <pre><code>drove -c local apps appinstances kill TEST_APP-1 AI-601d160e-c692-4ddd-8b7f-4c09b30ed02e\n</code></pre> <p>Sample Request Payload <pre><code>{\n    \"type\": \"STOP_INSTANCES\",\n    \"appId\" : \"TEST_APP-1\",//(1)!\n    \"instanceIds\" : [ \"AI-601d160e-c692-4ddd-8b7f-4c09b30ed02e\" ],//(2)!\n    \"skipRespawn\" : true,//(3)!\n    \"opSpec\": {//(4)!\n        \"timeout\": \"5m\",\n        \"parallelism\": 1,\n        \"failureStrategy\": \"STOP\"\n    }\n}\n</code></pre></p> <ol> <li>Application ID</li> <li>Instance ids to be stopped</li> <li>Do not spin up new containers to replace the stopped ones. This is set ot <code>false</code> by default.</li> <li>Operation spec as mentioned in Cluster Op Spec</li> </ol> <p>Sample response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"appId\": \"TEST_APP-1\"\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"applications/operations/#destroy-an-application","title":"Destroy an application","text":"<p>To remove an application deployment (<code>appName</code>-<code>version</code> combo) the <code>DESTROY</code> command can be issued.</p> <p>Preconditions:</p> <ul> <li>App should not exist in the cluster</li> </ul> <p>State Transition: </p> <ul> <li><code>MONITORING</code> \u2192 <code>DESTROY_REQUESTED</code> \u2192 <code>DESTROYED</code> \u2192 none</li> </ul> <p>To create an application, an Application Spec needs to be created first. </p> <p>Once ready, CLI command needs to be issued or the following payload needs to be sent:</p> Drove CLIJSON <pre><code>drove -c local apps destroy TEST_APP_1\n</code></pre> <p>Sample Request Payload <pre><code>{\n    \"type\": \"DESTROY\",\n    \"appId\" : \"TEST_APP-1\",//(1)!\n    \"opSpec\": {//(2)!\n        \"timeout\": \"5m\",\n        \"parallelism\": 2,\n        \"failureStrategy\": \"STOP\"\n    }\n}\n</code></pre></p> <ol> <li>Spec as mentioned in Application Specification</li> <li>Operation spec as mentioned in Cluster Op Spec</li> </ol> <p>Sample response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"appId\": \"TEST_APP-1\"\n    },\n    \"message\": \"success\"\n}\n</code></pre></p> <p>Warning</p> <p>All metadata for an app and it's instances are completely obliterated from Drove's storage once an app is destroyed</p>"},{"location":"applications/outage/","title":"Outage Detection and Recovery","text":"<p>Drove tracks all instances for an app deployment in the cluster. It will ensure the required number of containers is always running on the cluster.</p>"},{"location":"applications/outage/#instance-health-detection-and-tracking","title":"Instance health detection and tracking","text":"<p>Executor runs periodic health checks on the container according to check spec configuration. - Runs readiness checks to ensure container is started properly before declaring it healthy - Runs health checks on the container at regular intervals to ensure it is in operating condition</p> <p>Behavior for both is configured by setting the appropriate options in the application specification.</p> <p>Result of such health checks (both success and failure) are reported to the controller. Appropriate action is taken to shut down containers that fail readiness or health checks. </p>"},{"location":"applications/outage/#container-crash","title":"Container crash","text":"<p>If container for an application crashes, Drove will automatically spin up a container in it's place.</p>"},{"location":"applications/outage/#executor-node-hardware-failure","title":"Executor node hardware failure","text":"<p>If an executor node fails, instances running on that node will be lost. This is detected by the outage detector and new containers are spun up on other parts of the cluster.</p>"},{"location":"applications/outage/#executor-service-temporary-unavailability","title":"Executor service temporary unavailability","text":"<p>On restart, executor service reads the metadata embedded in the container and registers them. It performs a reconciliation with the leader controller to kill any local containers if the unavailability was too long and controller has already spun up new alternatives.</p>"},{"location":"applications/outage/#zombie-container-detection-and-cleanup","title":"Zombie (container) detection and cleanup","text":"<p>Executor service keeps track of all containers it is supposed to run by running periodic reconciliation with the leader controller. Any mismatch gets handled:</p> <ul> <li>if a container is found that is not supposed to be running, it is killed</li> <li>If a container that is supposed to be running is not found, it is marked as lost and reported to the controller. This triggers the controller to spin up an alternative container on the cluster.</li> </ul>"},{"location":"applications/specification/","title":"Application Specification","text":"<p>An application is defined using JSON. We use a sample configuration below to explain the options.</p>"},{"location":"applications/specification/#sample-application-definition","title":"Sample Application Definition","text":"<pre><code>{\n    \"name\": \"TEST_APP\", // (1)!\n    \"version\": \"1\", // (2)!\n    \"type\": \"SERVICE\", // (3)!\n    \"executable\": { //(4)!\n        \"type\": \"DOCKER\", // (5)!\n        \"url\": \"ghcr.io/appform-io/perf-test-server-httplib\",// (6)!\n        \"dockerPullTimeout\": \"100 seconds\"// (7)!\n    },\n    \"resources\": [//(20)!\n        {\n            \"type\": \"CPU\",\n            \"count\": 1//(21)!\n        },\n        {\n            \"type\": \"MEMORY\",\n            \"sizeInMB\": 128//(22)!\n        }\n    ],\n    \"volumes\": [//(12)!\n        {\n            \"pathInContainer\": \"/data\",//(13)!\n            \"pathOnHost\": \"/mnt/datavol\",//(14)!\n            \"mode\" : \"READ_WRITE\"//(15)!\n        }\n    ],\n    \"configs\" : [//(16)!\n        {\n            \"type\" : \"INLINE\",//(17)!\n            \"localFilename\": \"/testfiles/drove.txt\",//(18)!\n            \"data\" : \"RHJvdmUgdGVzdA==\"//(19)!\n        }\n    ],\n    \"placementPolicy\": {//(23)!\n        \"type\": \"ANY\"//(24)!\n    },\n    \"exposedPorts\": [//(8)!\n        {\n            \"name\": \"main\",//(9)!\n            \"port\": 8000,//(10)!\n            \"type\": \"HTTP\"//(11)!\n        }\n    ],\n    \"healthcheck\": {//(25)!\n        \"mode\": {//(26)!\n            \"type\": \"HTTP\", //(27)!\n            \"protocol\": \"HTTP\",//(28)!\n            \"portName\": \"main\",//(29)!\n            \"path\": \"/\",//(30)!\n            \"verb\": \"GET\",//(31)!\n            \"successCodes\": [//(32)!\n                200\n            ],\n            \"payload\": \"\", //(33)!\n            \"connectionTimeout\": \"1 second\" //(34)!\n        },\n        \"timeout\": \"1 second\",//(35)!\n        \"interval\": \"5 seconds\",//(36)!\n        \"attempts\": 3,//(37)!\n        \"initialDelay\": \"0 seconds\"//(38)!\n    },\n    \"readiness\": {//(39)!\n        \"mode\": {\n            \"type\": \"HTTP\",\n            \"protocol\": \"HTTP\",\n            \"portName\": \"main\",\n            \"path\": \"/\",\n            \"verb\": \"GET\",\n            \"successCodes\": [\n                200\n            ],\n            \"payload\": \"\",\n            \"connectionTimeout\": \"1 second\"\n        },\n        \"timeout\": \"1 second\",\n        \"interval\": \"3 seconds\",\n        \"attempts\": 3,\n        \"initialDelay\": \"0 seconds\"\n    },\n    \"exposureSpec\": {//(42)!\n        \"vhost\": \"testapp.local\", //(43)!\n        \"portName\": \"main\", //(44)!\n        \"mode\": \"ALL\"//(45)!\n    },\n    \"env\": {//(41)!\n        \"CORES\": \"8\"\n    },\n    \"tags\": { //(40)!\n        \"superSpecialApp\": \"yes_i_am\",\n        \"say_my_name\": \"heisenberg\"\n    },\n    \"preShutdown\": {//(46)!\n        \"hooks\": [ //(47)!\n            {\n                \"type\": \"HTTP\",\n                \"protocol\": \"HTTP\",\n                \"portName\": \"main\",\n                \"path\": \"/\",\n                \"verb\": \"GET\",\n                \"successCodes\": [\n                    200\n                ],\n                \"payload\": \"\",\n                \"connectionTimeout\": \"1 second\"\n            }\n        ],\n        \"waitBeforeKill\": \"3 seconds\"//(48)!\n    },\n    \"logging\": {//(49)!\n        \"type\": \"LOCAL\",//(50)!\n        \"maxSize\": \"100m\",//(51)!\n        \"maxFiles\": 3,//(52)!\n        \"compress\": true//(53)!\n    }\n}\n</code></pre> <ol> <li>A human readable name for the application. This will remain constant for different versions of the app.</li> <li>A version number. Drove does not enforce any format for this, but it is recommended to increment this for changes in spec.</li> <li>This should be fixed to <code>SERVICE</code> for an application/service.</li> <li>Coordinates for the executable. Refer to Executable Specification for details.</li> <li>Right now the only type supported is <code>DOCKER</code>.</li> <li>Docker container address</li> <li>Timeout for container pull.</li> <li>The ports to be exposed from the container.</li> <li>A logical name for the port. This will be used to reference this port in other sections.</li> <li>Actual port number as mentioned in Dockerfile.</li> <li>Type of port. Can be: <code>HTTP</code>, <code>HTTPS</code>, <code>TCP</code>, <code>UDP</code>.</li> <li>Volumes to be mounted. Refer to Volume Specification for details.</li> <li>Path that will be visible inside the container for this mount.</li> <li>Actual path on the host machine for the mount.</li> <li>Mount mode can be <code>READ_WRITE</code> and <code>READ_ONLY</code></li> <li>Configuration to be injected as file inside the container. Please refer to Config Specification for details.</li> <li>Type of config. Can be <code>INLINE</code>, <code>EXECUTOR_LOCAL_FILE</code>, <code>CONTROLLER_HTTP_FETCH</code> and <code>EXECUTOR_HTTP_FETCH</code>. Specifies how drove will get the contents to be injected..</li> <li>File name for the config inside the container.</li> <li>Serialized form of the data, this and other parameters will vary according to the <code>type</code> specified above.</li> <li>List of resources required to run this application. Check Resource Requirements Specification for more details.</li> <li>Number of CPU cores to be allocated.</li> <li>Amount of memory to be allocated expressed in Megabytes</li> <li>Specifies how the container will be placed on the cluster. Check Placement Policy for details.</li> <li>Type of placement can be <code>ANY</code>, <code>ONE_PER_HOST</code>, <code>MATCH_TAG</code>, <code>NO_TAG</code>, <code>RULE_BASED</code>, <code>ANY</code> and <code>COMPOSITE</code>. Rest of the parameters in this section will depend on the type.</li> <li>Health check to ensure service is running fine. Refer to Check Specification for details.</li> <li>Mode of health check, can be api call or command.</li> <li>Type of this check spec. Type can be <code>HTTP</code> or <code>CMD</code>. Rest of the options in this example are HTTP specific.</li> <li>API call protocol. Can be <code>HTTP</code>/<code>HTTPS</code></li> <li>Port name as mentioned in the <code>exposedPorts</code> section.</li> <li>HTTP path. Include query params here.</li> <li>HTTP method. Can be <code>GET</code>,<code>PUT</code> or <code>POST</code>.</li> <li>Set of HTTP status codes which can be considered as success.</li> <li>Payload to be sent for <code>POST</code> and <code>PUT</code> calls.</li> <li>Connection timeout for the port.</li> <li>Timeout for the check run.</li> <li>Interval between check runs.</li> <li>Max attempts after which the overall check is considered to be a failure.</li> <li>Time to wait before starting check runs.</li> <li>Readiness check to pass for the container to be considered as ready. Refer to Check Specification for details.</li> <li>Key value metadata that can be used in external systems.</li> <li>Custom environment variables. Additional variables are injected by Drove as well. See Environment Variables section for details.</li> <li>Specifies the virtual host on which this container is exposed.</li> <li>FQDN for the virtual host.</li> <li>Port name as specified in <code>exposedPorts</code> section.</li> <li>Mode for exposure. Set this to <code>ALL</code> for now.</li> <li>Things to do before a container is shutdown. Check Pre Shutdown Behavior for more details.</li> <li>Hooks (HTTP api call or shell command) to run before shutting down the container. Format is same as health/readiness checks. Refer to HTTP Check Actions and Command Check Options for details.</li> <li>Time to wait before killing the container. The container will be in <code>UNREADY</code> state during this time and hence won't have api calls routed to it via Drove Gateway.</li> <li>Specify how docker log files are configured. Refer to Logging Specification</li> <li>Log to local file</li> <li>Maximum File Size</li> <li>Number of latest log files to retain</li> <li>Log files will be compressed</li> </ol>"},{"location":"applications/specification/#executable-specification","title":"Executable Specification","text":"<p>Right now Drove supports only docker containers. However as engines, both docker and podman are supported. Drove executors will fetch the executable directly from the registry based on the configuration provided.</p> Name Option Description Type <code>type</code> Set type to <code>DOCKER</code>. URL <code>url</code> Docker container URL`. Timeout <code>dockerPullTimeout</code> Timeout for docker image pull. <p>Note</p> <p>Drove supports docker registry authentication. This can be configured in the executor configuration file.</p>"},{"location":"applications/specification/#resource-requirements-specification","title":"Resource Requirements Specification","text":"<p>This section specifies the hardware resources required to run the container. Right now only CPU and MEMORY are supported as resource types that can be reserved for a container.</p>"},{"location":"applications/specification/#cpu-requirements","title":"CPU Requirements","text":"<p>Specifies number of cores to be assigned to the container.</p> Name Option Description Type <code>type</code> Set type to <code>CPU</code> for this. Count <code>count</code> Number of cores to be assigned."},{"location":"applications/specification/#memory-requirements","title":"Memory Requirements","text":"<p>Specifies amount of memory to be allocated to a container.</p> Name Option Description Type <code>type</code> Set type to <code>MEMORY</code> for this. Count <code>sizeInMB</code> Amount of memory (in Mega Bytes) to be allocated. <p>Sample <pre><code>[\n    {\n        \"type\": \"CPU\",\n        \"count\": 1\n    },\n    {\n        \"type\": \"MEMORY\",\n        \"sizeInMB\": 128\n    }\n]\n</code></pre></p> <p>Note</p> <p>Both <code>CPU</code> and <code>MEMORY</code> configurations are mandatory.</p>"},{"location":"applications/specification/#volume-specification","title":"Volume Specification","text":"<p>Files and directories can be mounted from the executor host into the container. The <code>volumes</code> section contains a list of volumes that need to be mounted.</p> Name Option Description Path In Container <code>pathInContainer</code> Path that will be visible inside the container for this mount. Path On Host <code>pathOnHost</code> Actual path on the host machine for the mount. Mount Mode <code>mode</code> Mount mode can be <code>READ_WRITE</code> and <code>READ_ONLY</code> to allow the containerized process to write or read to the volume. <p>Info</p> <p>We do not support mounting remote volumes as of now.</p>"},{"location":"applications/specification/#config-specification","title":"Config Specification","text":"<p>Drove supports injection of configuration files into containers. The specifications for the same are discussed below.</p>"},{"location":"applications/specification/#inline-config","title":"Inline config","text":"<p>Inline configuration can be added in the Application Specification itself. This will manifest as a file inside the container.</p> <p>The following details are needed for this:</p> Name Option Description Type <code>type</code> Set the value to <code>INLINE</code> Local Filename <code>localFilename</code> File name for the config inside the container. Data <code>data</code> Base64 encoded string for the data. The value for this will be masked on UI. <p>Config file: <pre><code>port: 8080\nlogLevel: DEBUG\n</code></pre> Corresponding config specification: <pre><code>{\n    \"type\" : \"INLINE\",\n    \"localFilename\" : \"/config/service.yml\",\n    \"data\" : \"cG9ydDogODA4MApsb2dMZXZlbDogREVCVUcK\"\n}\n</code></pre></p> <p>Warning</p> <p>The full base 64 encoded config data will get stored in Drove ZK and will be pushed to executors inline. It is not recommended to stream large config files to containers using this method. This will probably need additional configuration on your ZK cluster.</p>"},{"location":"applications/specification/#locally-loaded-config","title":"Locally loaded config","text":"<p>Config file from a path on the executor directly. Such files can be distributed to the executor host using existing configuration management systems such as OpenTofu, Salt etc.</p> <p>The following details are needed for this:</p> Name Option Description Type <code>type</code> Set the value to <code>EXECUTOR_LOCAL_FILE</code> Local Filename <code>localFilename</code> File name for the config inside the container. File path <code>filePathOnHost</code> Path to the config file on executor host. <p>Sample config specification: <pre><code>{\n    \"type\" : \"EXECUTOR_LOCAL_FILE\",\n    \"localFilename\" : \"/config/service.yml\",\n    \"data\" : \"/mnt/configs/myservice/config.yml\"\n}\n</code></pre></p>"},{"location":"applications/specification/#controller-fetched-config","title":"Controller fetched Config","text":"<p>Config file can be fetched from a remote server by the controller. Once fetched, these will be streamed to the executor as part of the instance specification for starting a container.</p> <p>The following details are needed for this:</p> Name Option Description Type <code>type</code> Set the value to <code>CONTROLLER_HTTP_FETCH</code> Local Filename <code>localFilename</code> File name for the config inside the container. HTTP Call Details <code>http</code> HTTP Call related details. Please refer to HTTP Call Specification for details. <p>Sample config specification: <pre><code>{\n    \"type\" : \"CONTROLLER_HTTP_FETCH\",\n    \"localFilename\" : \"/config/service.yml\",\n    \"http\" : {\n        \"protocol\" : \"HTTP\",\n        \"hostname\" : \"configserver.internal.yourdomain.net\",\n        \"port\" : 8080,\n        \"path\" : \"/configs/myapp\",\n        \"username\" : \"appuser\",\n        \"password\" : \"secretpassword\"\n    }\n}\n</code></pre></p> <p>Note</p> <p>The controller will make an API call for every single time it asks an executor to spin up a container. Please make sure to account for this in your configuration management system.</p>"},{"location":"applications/specification/#executor-fetched-config","title":"Executor fetched Config","text":"<p>Config file can be fetched from a remote server by the executor before spinning up a container. Once fetched, the payload will be injected as a config file into the container.</p> <p>The following details are needed for this:</p> Name Option Description Type <code>type</code> Set the value to <code>EXECUTOR_HTTP_FETCH</code> Local Filename <code>localFilename</code> File name for the config inside the container. HTTP Call Details <code>http</code> HTTP Call related details. Please refer to HTTP Call Specification for details. <p>Sample config specification: <pre><code>{\n    \"type\" : \"EXECUTOR_HTTP_FETCH\",\n    \"localFilename\" : \"/config/service.yml\",\n    \"http\" : {\n        \"protocol\" : \"HTTP\",\n        \"hostname\" : \"configserver.internal.yourdomain.net\",\n        \"port\" : 8080,\n        \"path\" : \"/configs/myapp\",\n        \"username\" : \"appuser\",\n        \"password\" : \"secretpassword\"\n    }\n}\n</code></pre></p> <p>Note</p> <p>All executors will make an API call for every single time they spin up a container for this application. Please make sure to account for this in your configuration management system.</p>"},{"location":"applications/specification/#http-call-specification","title":"HTTP Call Specification","text":"<p>This section details the options that can set when making http calls to a configuration management system from controllers or executors.</p> <p>The following options are available for HTTP call:</p> Name Option Description Protocol <code>protocol</code> Protocol to use for upstream call. Can be <code>HTTP</code> or <code>HTTPS</code>. Hostname <code>hostname</code> Host to call. Port <code>port</code> Provide custom port. Defaults to 80 for http and 443 for https. API Path <code>path</code> Path component of the URL. Include query parameters here. Defaults to <code>/</code> HTTP Method <code>verb</code> Type of call, use <code>GET</code>, <code>POST</code> or <code>PUT</code>. Defaults to <code>GET</code>. Success Code <code>successCodes</code> List of HTTP status codes which is considered as success. Defaults to <code>[200]</code> Payload <code>payload</code> Data to be used for POST and PUT calls Connection Timeout <code>connectionTimeout</code> Timeout for upstream connection. Operation timeout <code>operationTimeout</code> Timeout for actual operation. Username <code>username</code> Username to be used basic auth. This field is masked out on the UI. Password <code>password</code> Password to be used for basic auth. This field is masked on the UI. Authorization Header <code>authHeader</code> Data to be passed in HTTP <code>Authorization</code> header. This field is masked on the UI. Additional Headers <code>headers</code> Any other headers to be passed to the upstream in the HTTP calls. This is a map of Skip SSL Checks <code>insecure</code> Skip hostname and certification checks during SSL handshake with the upstream."},{"location":"applications/specification/#placement-policy-specification","title":"Placement Policy Specification","text":"<p>Placement policy governs how Drove deploys containers on the cluster. The following sections discuss the different placement policies available and how they can be configured to achieve optimal placement of containers.</p> <p>Warning</p> <p>All policies will work only at a <code>{appName, version}</code> combination level. They will not ensure constraints at an <code>appName</code> level. This means that for somethinge like a one per node placement, for the same <code>appName</code>, multiple containers can run on the same host if multiple deployments with different <code>version</code>s are active in a cluster. Same applies for all policies like N per host and so on.</p> <p>Important details about executor tagging</p> <ul> <li>All hosts have at-least one tag, it's own hostname.</li> <li>The <code>TAG</code> policy will consider them as valid tags. This can be used to place containers on specific hosts if needed.</li> <li>This is handled specially in all other policy types and they will consider executors having only the hostname tag as untagged.</li> <li>A host with a tag (other than host) will not have any containers running if not placed on them specifically using the <code>MATCH_TAG</code> policy</li> </ul>"},{"location":"applications/specification/#any-placement","title":"Any Placement","text":"<p>Containers for a <code>{appName, version}</code> combination can run on any un-tagged executor host.</p> Name Option Description Policy Type <code>type</code> Put <code>ANY</code> as policy. <p>Sample: <pre><code>{\n    \"type\" : \"ANY\"\n}\n</code></pre></p> <p>Tip</p> <p>For most use-cases this is the placement policy to use.</p>"},{"location":"applications/specification/#one-per-host-placement","title":"One Per Host Placement","text":"<p>Ensures that only one container for a particular <code>{appName, version}</code> combination is running on an executor host at a time.</p> Name Option Description Policy Type <code>type</code> Put <code>ONE_PER_HOST</code> as policy. <p>Sample: <pre><code>{\n    \"type\" : \"ONE_PER_HOST\"\n}\n</code></pre></p>"},{"location":"applications/specification/#max-n-per-host-placement","title":"Max N Per Host Placement","text":"<p>Ensures that at most N containers for a <code>{appName, version}</code> combination is running on an executor host at a time.</p> Name Option Description Policy Type <code>type</code> Put <code>MAX_N_PER_HOST</code> as policy. Max count <code>max</code> The maximum num of containers that can run on an executor. Range: 1-64 <p>Sample: <pre><code>{\n    \"type\" : \"MAX_N_PER_HOST\",\n    \"max\": 3\n}\n</code></pre></p>"},{"location":"applications/specification/#match-tag-placement","title":"Match Tag Placement","text":"<p>Ensures that containers for a <code>{appName, version}</code> combination are running on an executor host that has the tags as mentioned in the policy.</p> Name Option Description Policy Type <code>type</code> Put <code>MATCH_TAG</code> as policy. Max count <code>tag</code> The tag to match. <p>Sample: <pre><code>{\n    \"type\" : \"MATCH_TAG\",\n    \"tag\": \"gpu_enabled\"\n}\n</code></pre></p>"},{"location":"applications/specification/#no-tag-placement","title":"No Tag Placement","text":"<p>Ensures that containers for a <code>{appName, version}</code> combination are running on an executor host that has no tags.</p> Name Option Description Policy Type <code>type</code> Put <code>NO_TAG</code> as policy. <p>Sample: <pre><code>{\n    \"type\" : \"NO_TAG\"\n}\n</code></pre></p> <p>Info</p> <p>The NO_TAG policy is mostly for internal use, and does not need to be specified when deploying containers that do not need any special placement logic.</p>"},{"location":"applications/specification/#composite-policy-based-placement","title":"Composite Policy Based Placement","text":"<p>Composite policy can be used to combine policies together to create complicated placement requirements.</p> Name Option Description Policy Type <code>type</code> Put <code>COMPOSITE</code> as policy. Polices <code>policies</code> List of policies to combine Combiner <code>combiner</code> Can be <code>AND</code> and <code>OR</code> and signify all-match and any-match logic on the <code>policies</code> mentioned. <p>Sample: <pre><code>{\n    \"type\" : \"COMPOSITE\",\n    \"policies\": [\n        {\n            \"type\": \"ONE_PER_HOST\"\n        },\n        {\n            \"type\": \"MATH_TAG\",\n            \"tag\": \"gpu_enabled\"\n        }\n    ],\n    \"combiner\" : \"AND\"\n}\n</code></pre> The above policy will ensure that only one container of the relevant <code>{appName,version}</code> will run on GPU enabled machines.</p> <p>Tip</p> <p>It is easy to go into situations where no executors match complicated placement policies. Internally, we tend to keep things rather simple and use the ANY placement for most cases and maybe tags in a few places with over-provisioning or for hosts having special hardware </p>"},{"location":"applications/specification/#environment-variables","title":"Environment variables","text":"<p>This config can be used to inject custom environment variables to containers. The values are defined as part of deployment specification, are same across the cluster and immutable to modifications from inside the container (ie any overrides from inside the container will not be visible across the cluster).</p> <p>Sample: <pre><code>{\n    \"MY_VARIABLE_1\": \"fizz\",\n    \"MY_VARIABLE_2\": \"buzz\"\n}\n</code></pre></p> <p>The following environment variables are injected by Drove to all containers:</p> Variable Name Value HOST Hostname where the container is running. This is for marathon compatibility. PORT_<code>PORT_NUMBER</code> A variable for every port specified in <code>exposedPorts</code> section. The value is the actual port on the host, the specified port is mapped to.  For example if ports 8080 and 8081 are specified, two variables called <code>PORT_8080</code> and <code>PORT_8081</code> will be injected. DROVE_EXECUTOR_HOST Hostname where container is running. DROVE_CONTAINER_ID Container that is deployed DROVE_APP_NAME App name as specified in the Application Specification DROVE_INSTANCE_ID Actual instance ID generated by Drove DROVE_APP_ID Application ID as generated by Drove DROVE_APP_INSTANCE_AUTH_TOKEN A JWT string generated by Drove that can be used by this container to call <code>/apis/v1/internal/...</code> apis. <p>Warning</p> <p>Do not pass secrets using environment variables. These variables are all visible on the UI as is. Please use Configs to inject secrets files and so on.</p>"},{"location":"applications/specification/#check-specification","title":"Check Specification","text":"<p>One of the cornerstones of managing applications on the cluster is to ensure we keep track of instance health and manage their life cycle depending on their health state. We need to define how to monitor health for containers accordingly. The checks will be executed on Applications and a Check result is generated. The result consists of the following:</p> <ul> <li>Status - Healthy, Unhealthy or Stopped if the container is already in stopping state</li> <li>Message - Any error message as generated by a specific checker</li> </ul>"},{"location":"applications/specification/#common-options","title":"Common Options","text":"Name Option Description Mode <code>mode</code> The definition of a HTTP call or a Command to be executed in the container. See following sections for details. Timeout <code>timeout</code> Duration for which we wait before declaring a check as failed Interval <code>interval</code> Interval at which check will be retried Attempts <code>attempts</code> Number of times a check is retried before it is declared as a failure Initial Delay <code>initialDelay</code> Delay before executing the check for the first time. <p>Note</p> <p><code>initialDelay</code> is ignored when readiness checks and health checks are run in the recovery path as the container is already running at that point in time.</p>"},{"location":"applications/specification/#http-check-options","title":"HTTP Check Options","text":"Name Option Description Type <code>type</code> Fixed to HTTP for HTTP checker Protocol <code>protocol</code> HTTP or HTTPS call to be made Port Name <code>portName</code> The name of the container port to make the http call on as specified in the Exposed Ports section in Application Spec Path <code>path</code> The api path to call HTTP method <code>verb</code> The HTTP Verb/Method to invoke. GET/PUT and POST are supported here Success Codes <code>successCodes</code> A set of HTTP status codes that we should consider as a success from this API. Payload <code>payload</code> A string payload that we can pass if the Verb is POST or PUT Connection Timeout <code>connectionTimeout</code> Maximum time for which the checker will wait for the connection to be set up with the container. Insecure <code>insecure</code> Skip hostname and certificate checks for HTTPS ports during checks."},{"location":"applications/specification/#command-check-options","title":"Command Check Options","text":"Field Option Description Type <code>type</code> Fixed to CMD for command checker Command <code>command</code> Command to execute in the container. (Equivalent to <code>docker exec -it &lt;container&gt; command&gt;</code>)"},{"location":"applications/specification/#exposure-specification","title":"Exposure Specification","text":"<p>Exposure spec is used to specify the virtual host Drove Gateway exposes to outside world for communication with the containers.</p> <p>The following information needs to be specified:</p> Name Option Description Virtual Host <code>vhost</code> The virtual host to be exposed on NGinx. This should be a fully qualified domain name. Port Name <code>portName</code> The portname to be exposed on the vhost. Port names are defined in <code>exposedPorts</code> section. Exposure Mode <code>mode</code> Use <code>ALL</code> here for now. Signifies that all healthy instances of the app are exposed to traffic. <p>Sample: <pre><code>{\n    \"vhost\": \"teastapp.mydomain\",\n    \"port\": \"main\",\n    \"mode\": \"ALL\"\n}\n</code></pre></p> <p>Note</p> <p>Application instances in any state other than <code>HEALTHY</code> are not considered for exposure. Please check Application Instance State Machine for an understanding of states of instances.</p>"},{"location":"applications/specification/#configuring-pre-shutdown-bheaviour","title":"Configuring Pre Shutdown Bheaviour","text":"<p>Before a container is shut down, it is desirable to ensure things are spun down properly. This behaviour can be configured in the <code>preShutdown</code> section of the configuration.</p> Name Option Description Hooks <code>hooks</code> List of api calls and commands to be run on the container before it is killed. Each hook is either a HTTP Call Spec or Command Spec Wait Time <code>waitBeforeKill</code> Time to wait before killing the container. <p>Sample <pre><code>{\n    \"hooks\": [\n        {\n            \"type\": \"HTTP\",\n            \"protocol\": \"HTTP\",\n            \"portName\": \"main\",\n            \"path\": \"/\",\n            \"verb\": \"GET\",\n            \"successCodes\": [\n                200\n            ],\n            \"payload\": \"\",\n            \"connectionTimeout\": \"1 second\"\n        }\n    ],\n    \"waitBeforeKill\": \"3 seconds\"//(48)!\n}\n</code></pre></p> <p>Note</p> <p>The <code>waitBeforeKill</code> timed wait kicks in after all the hooks have been executed.</p>"},{"location":"applications/specification/#logging-specification","title":"Logging Specification","text":"<p>Can be used to configure how container logs are managed on the system. </p> <p>Note</p> <p>This section affects the docker log driver. Drove will continue to stream logs to it's own logger which can be configured at executor level through the executor configuration file.</p>"},{"location":"applications/specification/#local-logger-configuration","title":"Local Logger configuration","text":"<p>This is used to configure the <code>json-file</code> log driver.</p> Name Option Description Type <code>type</code> Set the value to <code>LOCAL</code> Max Size <code>maxSize</code> Maximum file size. Anything bigger than this will lead to rotation. Max Files <code>maxFiles</code> Maximum number of logs files to keep. Range: 1-100 Compress <code>compress</code> Enable log file compression. <p>Tip</p> <p>If <code>logging</code> section is omitted, the following configuration is applied by default: - File size: 10m - Number of files: 3 - Compression: on</p>"},{"location":"applications/specification/#rsyslog-configuration","title":"Rsyslog configuration","text":"<p>In case suers want to stream logs to an rsyslog server, the logging configuration needs to be set to RSYSLOG mode.</p> Name Option Description Type <code>type</code> Set the value to <code>RSYSLOG</code> Server <code>server</code> URL for the rsyslog server. Tag Prefix <code>tagPrefix</code> Prefix to add at the start of a tag Tag Suffix <code>tagSuffix</code> Suffix to add at the en of a tag. <p>Note</p> <p>The default tag is the <code>DROVE_INSTANCE_ID</code>. The <code>tagPrefix</code> and <code>tagSuffix</code> will to before and after this</p>"},{"location":"cluster/cluster/","title":"Anatomy of a Drove Cluster","text":"<p>The following diagram provides a high level overview of a typical Drove cluster.  The overall topology consists of the following components:</p> <ul> <li>An Apache ZooKeeper cluster for state persistence and coordination</li> <li>A set of controller nodes one of which (the leader) manages the cluster</li> <li>A set of executor nodes on which the containers actually execute</li> <li>NGinx + drove-nixy nodes that expose virtual hosts for the leader controller as well as for the vhosts defined for the various applications running on the cluster</li> </ul>"},{"location":"cluster/cluster/#apache-zookeeper","title":"Apache ZooKeeper","text":"<p>Zookeeper is a central component in a Drove cluster. It is used in the following manner:</p> <ul> <li>As store for discovery of cluster components like Controller and Executor to each other</li> <li>For electing the leader controller in the cluster</li> <li>As storage for Application and Task Specifications</li> <li>Asynchronous communication channel/transient store for real-time information about controller and executor state in the cluster</li> </ul>"},{"location":"cluster/cluster/#controller","title":"Controller","text":"<p>The controller service is the brains of a Drove cluster. The role of the controller consists of the following:</p> <ul> <li>Ensure it has a reasonably up-to-date information about the cluster topology and free/used resources</li> <li>Track executor status (blacklisted/online/offline etc) and tagging. - Take corrective actions in case some of them become inaccessible for whatever reason</li> <li>Manages container placement to ensure that application and task containers get placed according to provided placement configuration/spec</li> <li>Manage NUMA node and core affinity ensuring that instances get deployed optimally on cores and NUMA nodes without stepping on each other</li> <li>Provide a UI for users to consume data about cluster, applications and tasks</li> <li>Provide APIs for systems to provision apps, tasks and manage the cluster</li> <li>Provide event stream for other tools and services to follow what is happening on the cluster</li> <li>Provide APIs to list container level logs and provide real-time offset based polling of log contents for application and task instances</li> <li>Implement leader election based HA so that only one controller is active(leader) at a time.</li> <li>All decisions regarding scheduling, state machine management and recovery are taken only by the leader</li> <li>Manage the lifecycle of all applications deployed on the cluster.<ul> <li>Maintain the required number of application instances as specified during deployment. This means that the controller has to monitor all applications running on all nodes and replace any instances or kill any spurious ones to ensure a constant number of instances on the cluster. The required number of instances is maintained as expected count, the current number of instances is maintained as running count.</li> <li>Provide a way to adjust the number of instances for this application. This would help in users being able to scale applications up and down as needed.</li> <li>Provide a way to restart all instances of the application. This would mean the controller would have to orchestrate a continuous string of start-kill operations across instances running on the cluster.</li> <li>Graceful shutdown/suspension of application across the cluster. This comes as a natural extension of the above and is mostly a scale down operation with the expected count set as zero.</li> </ul> </li> <li>Manage task lifecycle<ul> <li>Maintain task state-machine by scheduling it on executors and ensuring it reaches terminal state</li> <li>Provide mechanisms to cancel tasks</li> </ul> </li> <li>Reconcile stale and dead instances for applications and tasks and take corrective measures to ensure steady state if necessary</li> <li>Application instance migration from blacklisted executors</li> <li>Send command messages to executors to start and stop instances with retries and failure recovery</li> </ul>"},{"location":"cluster/cluster/#executors","title":"Executors","text":"<p>Executors are the agents running on the nodes where the containers are deployed. Role of the executors is the following:</p> <ul> <li>Publish hardware topology of the machine to the controller on startup.</li> <li>Manage container lifecycle including:<ul> <li>Pulling containers from docker repository with optional authentication</li> <li>Start containers with proper options for pinning containers to specific NUMA nodes and cores as specified by controller<ul> <li>Data for an instance is stored as specific docker label values on the containers themselves</li> </ul> </li> <li>Run HTTP call or shell command based readiness checks to ensure application container is ready to serve traffic based on readiness checks specification in start message</li> <li>Monitor application container health by running periodic HTTP call or shell command based health checks as specified by controller in start message</li> <li>Track normal (for tasks) or abnormal (for application instances) container exits. <ul> <li>For tasks, the exit code is collected and used to deduce if task succeeded (exit code is 0) or failed (exit code is non-zero)</li> <li>For application containers, the expectation is for the container to stop only when explicitly requested and hence all exits are considered as failures and handled accordingly</li> </ul> </li> <li>Stop application containers on request from controller</li> <li>Run any pre-shutdown hook calls as specified in the application specification before killing container</li> <li>Cleanup container volumes etc</li> <li>Cleanup docker images (if local image caching is turned off which is the default behaviour)</li> </ul> </li> <li>Send regular local node status updates to ZooKeeper every 20 seconds</li> <li>Send instant updates by making direct HTTP calls to the leader controller when anything changes for any running containers and for every step of the container state machine execution for both task and application instances to allow for faster updates</li> <li>Recover containers on process restart based on the metadata stored as labels on the running container. This data is reconciled with a snapshot of the expected instances on the node as received from the leader controller at that point in time.</li> <li>Find and kill any zombie containers that are not supposed to exist on that node. The check is done every 30 seconds.</li> <li>Provide container log-file listing and offset based content delivery APIs to container</li> </ul>"},{"location":"cluster/cluster/#nginx-and-drove-nixy","title":"NGinx and Drove-Nixy","text":"<p>Almost all of the traffic between service containers is routed via the internal Ranger based service discovery system at PhonePe. However, traffic from the edge as well and between different protected environments are routed using the well-established virtual host (and additionally, in some unusual cases, header) based routing.</p> <ul> <li>All applications on Drove can specify a Vhost and a port name as endpoint for such routing.</li> <li>Upstream information for such VHosts or endpoints is available from an API from the leading Drove controller.</li> <li>This information can be used to configure any load-balancer or tourer or reverse proxy to expose applications running on Drove to the outside world.</li> <li> <p>We modified an existing project called Nixy so that it gets the upstream information from Drove instead of Marathon. Nixy plays the following role in a cluster:</p> </li> <li> <p>Track the leader controller for a Drove cluster by making ping calls to all specified controllers</p> </li> <li>Provide a special data structure that can be used by a template to expose a vhost that points to the leader controller in a Drove cluster. This can be used for any tools that need to interact with a Drove cluster for deployments, monitoring as well as callback endpoints for OAuth etc etc</li> <li>Listen to relevant events from the Drove cluster to trigger up[stream refresh as necessary</li> <li>Provide data structures that include the vhost, upstream endpoints (host:port) and metadata (application level tags) that can be used to build templates that generate NGinx configurations to enable progressively complicated routing of calls from downstream to upstreams hosted on Drove clusters. Data structure exposed to templates, groups all upstream host:port tuples by using the vhost. This allows for multiple deployments for the same VHost to exist. This is needed for a variety of situations including online-updates of services.</li> <li>Supports username/password based authentication and header based (used internally) to Drove clusters.</li> <li>Support for both NGinx Plus and OSS products. Drove-Nixy can make appropriate api calls to corresponding NGinx plus server to only refresh existing VHost on topology change, as well as affect a full reload when new Vhosts are detected. This ensures that there are no connection drops for critical path applications where NGinx Plus might be used. This also solves the issue of NGinx workers going into a hung state due to frequent reloads on busy clusters like our dev testing environment.</li> </ul> <p>Tip</p> <p>The NGinx deployment is standard across all Drove clusters. However, for clusters that receive a lot of traffic using Nginx, the cluster exposing the VHost for Drove itself might be separated from the one exposing the application virtual hosts to allow for easy scalability of the latter. The template for these are configured differently as needed respectively.</p>"},{"location":"cluster/cluster/#other-components","title":"Other components","text":"<p>There are a few more components that are used for operational management and observability.</p>"},{"location":"cluster/cluster/#telegraf","title":"Telegraf","text":"<p>PhonePe\u2019s internal metric management system uses a HTTP based metric collector. Telegraf is installed on all Drove nodes to collect metric from the metric port (Admin connector on Dropwizard) and push that information to our metric ingestion system. This information is then used to build dashboards as well as by our Anomaly detection and alerting systems.</p>"},{"location":"cluster/cluster/#log-management","title":"Log Management","text":"<p>Drove provides a special logger called drove that can be configured to handle compression rotation and archival of container logs. Such container logs are stored on specialised partitions by application/application-instance-id or by source app name/ task id for application and task instances respectively. PhonePe\u2019s standardised log rotation tools are used to monitor and ship out such logs to our central log management system. The same can be replaced or enhanced by running something like promtail on Drove logs to ship out logs to tools like Grafana Loki.</p>"},{"location":"cluster/operations/","title":"Operations","text":"<p>Operations on a cluster can be used to manage the life cycle of Applications and Tasks.</p>"},{"location":"cluster/operations/#cluster-operation-specification","title":"Cluster Operation Specification","text":"<p>When an operation is submitted to the cluster, a cluster op spec needs to be specified. This is needed to control different aspects of the operation, including parallelism of an operation or increase the timeout for the operation and so on. </p> <p>The following aspects of an operation can be configured:</p> Name Option Description Timeout <code>timeout</code> The duration after which Drove considers the operation to have timed out. Parallelism <code>parallelism</code> Parallelism of the task. (Range: 1-32) Failure Strategy <code>failureStrategy</code> Set this to <code>STOP</code>. <p>Note</p> <p>For internal recovery operations, Drove generates it's own operations. For that, Drove applies the following cluster operation spec:</p> <ul> <li>timeout - 300 seconds</li> <li>parallelism - 1</li> <li>failureStrategy - <code>STOP</code></li> </ul> <p>The default operation spec can be configured in the controller configuration file. It is recommended to set this to a something like 8 for faster recovery.</p> <p>Please check Application Operations and Task Operations for individual operations.</p>"},{"location":"tasks/","title":"Introduction","text":"<p>A task is a representation for transient containerized workloads on the cluster. A task instance is supposed to have a much shorter life-time than an application instance. Use tasks to spin up things like automation scripts etc.</p>"},{"location":"tasks/#primary-differences-with-an-application","title":"Primary differences with an application","text":"<p>Please note the following important differences between a task instance and application instances</p> <ul> <li>Tasks cannot expose ports and virtual hosts for incoming traffic</li> <li>There are no readiness checks, health checks or shutdown hooks for a task</li> <li>Task instances cannot be scaled up or down</li> <li>Tasks cannot be restarted</li> <li>A task is typically owned by an application running on the cluster.</li> <li>Task instances are not replaced if the corresponding executor node goes down during execution</li> <li>Unlike applications there is no task + task instance, the only representation of task on a Drove cluster is a task instance.</li> </ul> <p>Tip</p> <p>Use epoch to spin up tasks in a periodic manner</p> <p>A task specification contains the following sections:</p> <ul> <li>Source App Name - Name of the application that created this task</li> <li>Task ID - User supplied task ID unique in the same <code>sourceAppName</code> scope</li> <li>Executable - The container to deploy on the cluster</li> <li>Resources - CPU and Memory required for the container</li> <li>Placement Policy - How containers are to be placed in the cluster</li> <li>Environment Variables - Environment variables and values</li> <li>Volumes - Volumes to be mounted into the container</li> <li>Configs - Configs/files to be mounted into the container</li> <li>Logging details - Logging spec (for example rsyslog server)</li> <li>Tags - A map of strings for additional metadata</li> </ul>"},{"location":"tasks/#task-id","title":"Task ID","text":"<p>Identification of a task is a bit more complicated on Drove. There is a Task ID (<code>{sourceAppName}-{taskId}</code>) which is used internally in drove. This is returned to the client when task is created.</p> <p>However, clients are supposed to use the <code>{sourceAppName,taskId}</code> combo they have sent in the task spec to address and send commands to their tasks.</p>"},{"location":"tasks/#task-states-and-operations","title":"Task States and operations","text":"<p>Tasks on Drove have their own life cycle modelled as a state machine. State transitions can be triggered by issuing operations using the APIs.</p>"},{"location":"tasks/#states","title":"States","text":"<p>Tasks on a Drove cluster can be one of the following states:</p> <ul> <li>PENDING - Task has been submitted, yet to be provisioned</li> <li>PROVISIONING - Task is assigned to an executor and docker image i ng -ownloaded</li> <li>PROVISIONING_FAILED - Docker image download failed</li> <li>STARTING - Docker run is starting</li> <li>RUNNING - Task is running currently</li> <li>RUN_COMPLETED - Task run has completed. Whether passed or failed n -o be checked from the task result.</li> <li>DEPROVISIONING - Docker image cleanup underway</li> <li>STOPPED - Task cleanup completed. This is a terminal state.</li> <li>LOST - Task disappeared while executor was down.</li> <li>UNKNOWN - All tasks that are running are put in this state when executor has been restarted and startup recovery has not kicked in yet</li> </ul>"},{"location":"tasks/#operations","title":"Operations","text":"<p>The following task operations are recognized by Drove:</p> <ul> <li>CREATE - Create a task. The Task definition/spec is provided as an argument to this.</li> <li>KILL - Kill a task. The task ID is taken as a parameter.</li> </ul> <p>Tip</p> <p>All operations need Cluster Operation Spec which can be used to control the timeout and parallelism of tasks generated by the operation.</p>"},{"location":"tasks/#task-state-machine","title":"Task State Machine","text":"<p>The following state machine signifies the states and transitions as affected by cluster state and operations issued.</p> <p></p>"},{"location":"tasks/operations/","title":"Task Operations","text":"<p>This page discusses operations relevant to Task management. Please go over the Task State Machine to understand the different states a task  can be in and how operations applied (and external changes) move a task from one state to another.</p> <p>Note</p> <p>Please go through Cluster Op Spec to understand the operation parameters being sent.</p> <p>For tasks only the <code>timeout</code> parameter is relevant.</p> <p>Note</p> <p>Only one operation can be active on a particular task identified by a <code>{sourceAppName,taskId}</code> at a time.</p> <p>Warning</p> <p>Only the leader controller will accept and process operations. To avoid confusion, use the controller endpoint exposed by Drove Gateway to issue commands.</p>"},{"location":"tasks/operations/#how-to-initiate-an-operation","title":"How to initiate an operation","text":"<p>Tip</p> <p>Use the Drove CLI to perform all manual operations.</p> <p>All operations for task lifecycle management need to be issued via a POST HTTP call to the leader controller endpoint on the path <code>/apis/v1/tasks/operations</code>. API will return HTTP OK/200 and relevant json response as payload.</p> <p>Sample api call:</p> <pre><code>curl --location 'http://drove.local:7000/apis/v1/tasks/operations' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Basic YWRtaW46YWRtaW4=' \\\n--data '{\n    \"type\": \"KILL\",\n    \"sourceAppName\" : \"TEST_APP\",\n    \"taskId\" : \"T0012\",\n    \"opSpec\": {\n        \"timeout\": \"5m\",\n        \"parallelism\": 1,\n        \"failureStrategy\": \"STOP\"\n    }\n}'\n</code></pre> <p>Note</p> <p>In the above examples, <code>http://drove.local:7000</code> is the endpoint of the leader. <code>TEST_APP</code> is the <code>name</code> of the application that started this task and <code>taskId</code> is a unique client generated id. Authorization is basic auth.</p> <p>Warning</p> <p>Task operations are not cancellable.</p>"},{"location":"tasks/operations/#create-a-task","title":"Create a task","text":"<p>A task can be created issuing the following command.</p> <p>Preconditions: - Task with same <code>{sourceAppName,taskId}</code> should not exist on the cluster.</p> <p>State Transition:</p> <ul> <li>none \u2192 <code>PENDING</code> \u2192 <code>PROVISIONING</code> \u2192 <code>STARTING</code> \u2192 <code>RUNNING</code> \u2192 <code>RUN_COMPLETED</code> \u2192 <code>DEPROVISIONING</code> \u2192 <code>STOPPED</code></li> </ul> <p>To create a task a Task Spec needs to be created first.</p> <p>Once ready, CLI command needs to be issued or the following payload needs to be sent:</p> Drove CLIJSON <pre><code>drove -c local tasks create sample/test_task.json\n</code></pre> <p>Sample Request Payload <pre><code>{\n    \"type\": \"CREATE\",\n    \"spec\": {...}, //(1)!\n    \"opSpec\": { //(2)!\n        \"timeout\": \"5m\",\n        \"parallelism\": 1,\n        \"failureStrategy\": \"STOP\"\n    }\n}\n</code></pre></p> <ol> <li>Spec as mentioned in Task Specification</li> <li>Operation spec as mentioned in Cluster Op Spec</li> </ol> <p>Sample response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"taskId\": \"TEST_APP-T0012\"\n    },\n    \"message\": \"success\"\n}\n</code></pre></p> <p>Warning</p> <p>There are no separate create/run steps in a task. Creation will start execution automatically and immediately.</p>"},{"location":"tasks/operations/#kill-a-task","title":"Kill a task","text":"<p>A task can be created issuing the following command.</p> <p>Preconditions: - Task with same <code>{sourceAppName,taskId}</code> needs to exist on the cluster.</p> <p>State Transition:</p> <ul> <li><code>RUNNING</code> \u2192 <code>RUN_COMPLETED</code> \u2192 <code>DEPROVISIONING</code> \u2192 <code>STOPPED</code></li> </ul> <p>CLI command needs to be issued or the following payload needs to be sent:</p> Drove CLIJSON <pre><code>drove -c local tasks kill TEST_APP T0012\n</code></pre> <p>Sample Request Payload <pre><code>{\n    \"type\": \"KILL\",\n    \"sourceAppName\" : \"TEST_APP\",//(1)!\n    \"taskId\" : \"T0012\",//(2)!\n    \"opSpec\": {//(3)!\n        \"timeout\": \"5m\",\n        \"parallelism\": 1,\n        \"failureStrategy\": \"STOP\"\n    }\n}\n</code></pre></p> <ol> <li>Source app name as mentioned in spec during task creation</li> <li>Task ID as mentioned in the spec</li> <li>Operation spec as mentioned in Cluster Op Spec</li> </ol> <p>Sample response <pre><code>{\n    \"status\": \"SUCCESS\",\n    \"data\": {\n        \"taskId\": \"T0012\"\n    },\n    \"message\": \"success\"\n}\n</code></pre></p> <p>Note</p> <p>Task metadata will remain on the cluster for some time. Metadata cleanup for tasks is automatic and can be configured in the controller configuration.</p>"},{"location":"tasks/specification/","title":"Task Specification","text":"<p>A task is defined using JSON. We use a sample configuration below to explain the options.</p>"},{"location":"tasks/specification/#sample-task-definition","title":"Sample Task Definition","text":"<pre><code>{\n    \"sourceAppName\": \"TEST_APP\",//(1)!\n    \"taskId\": \"T0012\",//(2)!\n    \"executable\": {//(3)!\n        \"type\": \"DOCKER\", // (4)!\n        \"url\": \"ghcr.io/appform-io/test-task\",//(5)!\n        \"dockerPullTimeout\": \"100 seconds\"//(6)!\n    },\n     \"resources\": [//(7)!\n        {\n            \"type\": \"CPU\",\n            \"count\": 1//(8)!\n        },\n        {\n            \"type\": \"MEMORY\",\n            \"sizeInMB\": 128//(9)!\n        }\n    ],\n    \"volumes\": [//(10)!\n        {\n            \"pathInContainer\": \"/data\",//(11)!\n            \"pathOnHost\": \"/mnt/datavol\",//(12)!\n            \"mode\" : \"READ_WRITE\"//(13)!\n        }\n    ],\n    \"configs\" : [//(14)!\n        {\n            \"type\" : \"INLINE\",//(15)!\n            \"localFilename\": \"/testfiles/drove.txt\",//(16)!\n            \"data\" : \"RHJvdmUgdGVzdA==\"//(17)!\n        }\n    ],\n    \"placementPolicy\": {//(18)!\n        \"type\": \"ANY\"//(19)!\n    },\n    \"env\": {//(20)!\n        \"CORES\": \"8\"\n    },\n    \"tags\": { //(21)!\n        \"superSpecialApp\": \"yes_i_am\",\n        \"say_my_name\": \"heisenberg\"\n    },\n    \"logging\": {//(22)!\n        \"type\": \"LOCAL\",//(23)!\n        \"maxSize\": \"100m\",//(24)!\n        \"maxFiles\": 3,//(25)!\n        \"compress\": true//(26)!\n    }\n}\n</code></pre> <ol> <li>Name of the <code>application</code> that has started the task. Make sure this is a valid application on the cluster.</li> <li>An unique ID for this task. Uniqueness is up to the user, Drove will scope it in the <code>sourceAppName</code> namespace.</li> <li>Coordinates for the executable. Refer to Executable Specification for details.</li> <li>Right now the only type supported is <code>DOCKER</code>.</li> <li>Docker container address</li> <li>Timeout for container pull.</li> <li>Volumes to be mounted. Refer to Volume Specification for details.</li> <li>Path that will be visible inside the container for this mount.</li> <li>Actual path on the host machine for the mount.</li> <li>Mount mode can be <code>READ_WRITE</code> and <code>READ_ONLY</code></li> <li>Configuration to be injected as file inside the container. Please refer  Config Specification for details.</li> <li>Type of config. Can be <code>INLINE</code>, <code>EXECUTOR_LOCAL_FILE</code>, ONTROLLER_HTTP_FETCH<code>and</code>EXECUTOR_HTTP_FETCH`. Specifies how drove will t the contents to be injected..</li> <li>File name for the config inside the container.</li> <li>Serialized form of the data, this and other parameters will vary cording to the <code>type</code> specified above.</li> <li>List of resources required to run this application. Check Resource Requirements Specification for more tails.</li> <li>Number of CPU cores to be allocated.</li> <li>Amount of memory to be allocated expressed in Megabytes</li> <li>Specifies how the container will be placed on the cluster. Check Placement Policy for details.</li> <li>Type of placement can be <code>ANY</code>, <code>ONE_PER_HOST</code>, <code>MATCH_TAG</code>, <code>NO_TAG</code>, <code>RULE_BASED</code>, <code>ANY</code> and <code>COMPOSITE</code>. Rest of the parameters in this section will depend on the type.</li> <li>Custom environment variables. Additional variables are injected by Drove  as well. See Environment Variables section for tails.</li> <li>Key value metadata that can be used in external systems.</li> <li>Specify how docker log files are configured. Refer to Logging Specification</li> <li>Log to local file</li> <li>Maximum File Size</li> <li>Number of latest log files to retain</li> <li>Log files will be compressed</li> </ol> <p>Warning</p> <p>Please make sure <code>sourceAppName</code> is set to a correct application name as specified in the <code>name</code> parameter of a running application on the cluster.</p> <p>If this is not done, stale task metadata will not be cleaned up and your metadata store performance will get affected over time.</p>"},{"location":"tasks/specification/#executable-specification","title":"Executable Specification","text":"<p>Right now Drove supports only docker containers. However as engines, both docker and podman are supported. Drove executors will fetch the executable directly from the registry based on the configuration provided.</p> Name Option Description Type <code>type</code> Set type to <code>DOCKER</code>. URL <code>url</code> Docker container URL`. Timeout <code>dockerPullTimeout</code> Timeout for docker image pull. <p>Note</p> <p>Drove supports docker registry authentication. This can be configured in the executor configuration file.</p>"},{"location":"tasks/specification/#resource-requirements-specification","title":"Resource Requirements Specification","text":"<p>This section specifies the hardware resources required to run the container. Right now only CPU and MEMORY are supported as resource types that can be reserved for a container.</p>"},{"location":"tasks/specification/#cpu-requirements","title":"CPU Requirements","text":"<p>Specifies number of cores to be assigned to the container.</p> Name Option Description Type <code>type</code> Set type to <code>CPU</code> for this. Count <code>count</code> Number of cores to be assigned."},{"location":"tasks/specification/#memory-requirements","title":"Memory Requirements","text":"<p>Specifies amount of memory to be allocated to a container.</p> Name Option Description Type <code>type</code> Set type to <code>MEMORY</code> for this. Count <code>sizeInMB</code> Amount of memory (in Mega Bytes) to be allocated. <p>Sample <pre><code>[\n    {\n        \"type\": \"CPU\",\n        \"count\": 1\n    },\n    {\n        \"type\": \"MEMORY\",\n        \"sizeInMB\": 128\n    }\n]\n</code></pre></p> <p>Note</p> <p>Both <code>CPU</code> and <code>MEMORY</code> configurations are mandatory.</p>"},{"location":"tasks/specification/#volume-specification","title":"Volume Specification","text":"<p>Files and directories can be mounted from the executor host into the container. The <code>volumes</code> section contains a list of volumes that need to be mounted.</p> Name Option Description Path In Container <code>pathInContainer</code> Path that will be visible inside the container for this mount. Path On Host <code>pathOnHost</code> Actual path on the host machine for the mount. Mount Mode <code>mode</code> Mount mode can be <code>READ_WRITE</code> and <code>READ_ONLY</code> to allow the containerized process to write or read to the volume. <p>Info</p> <p>We do not support mounting remote volumes as of now.</p>"},{"location":"tasks/specification/#config-specification","title":"Config Specification","text":"<p>Drove supports injection of configuration files into containers. The specifications for the same are discussed below.</p>"},{"location":"tasks/specification/#inline-config","title":"Inline config","text":"<p>Inline configuration can be added in the Application Specification itself. This will manifest as a file inside the container.</p> <p>The following details are needed for this:</p> Name Option Description Type <code>type</code> Set the value to <code>INLINE</code> Local Filename <code>localFilename</code> File name for the config inside the container. Data <code>data</code> Base64 encoded string for the data. The value for this will be masked on UI. <p>Config file: <pre><code>port: 8080\nlogLevel: DEBUG\n</code></pre> Corresponding config specification: <pre><code>{\n    \"type\" : \"INLINE\",\n    \"localFilename\" : \"/config/service.yml\",\n    \"data\" : \"cG9ydDogODA4MApsb2dMZXZlbDogREVCVUcK\"\n}\n</code></pre></p> <p>Warning</p> <p>The full base 64 encoded config data will get stored in Drove ZK and will be pushed to executors inline. It is not recommended to stream large config files to containers using this method. This will probably need additional configuration on your ZK cluster.</p>"},{"location":"tasks/specification/#locally-loaded-config","title":"Locally loaded config","text":"<p>Config file from a path on the executor directly. Such files can be distributed to the executor host using existing configuration management systems such as OpenTofu, Salt etc.</p> <p>The following details are needed for this:</p> Name Option Description Type <code>type</code> Set the value to <code>EXECUTOR_LOCAL_FILE</code> Local Filename <code>localFilename</code> File name for the config inside the container. File path <code>filePathOnHost</code> Path to the config file on executor host. <p>Sample config specification: <pre><code>{\n    \"type\" : \"EXECUTOR_LOCAL_FILE\",\n    \"localFilename\" : \"/config/service.yml\",\n    \"data\" : \"/mnt/configs/myservice/config.yml\"\n}\n</code></pre></p>"},{"location":"tasks/specification/#controller-fetched-config","title":"Controller fetched Config","text":"<p>Config file can be fetched from a remote server by the controller. Once fetched, these will be streamed to the executor as part of the instance specification for starting a container.</p> <p>The following details are needed for this:</p> Name Option Description Type <code>type</code> Set the value to <code>CONTROLLER_HTTP_FETCH</code> Local Filename <code>localFilename</code> File name for the config inside the container. HTTP Call Details <code>http</code> HTTP Call related details. Please refer to HTTP Call Specification for details. <p>Sample config specification: <pre><code>{\n    \"type\" : \"CONTROLLER_HTTP_FETCH\",\n    \"localFilename\" : \"/config/service.yml\",\n    \"http\" : {\n        \"protocol\" : \"HTTP\",\n        \"hostname\" : \"configserver.internal.yourdomain.net\",\n        \"port\" : 8080,\n        \"path\" : \"/configs/myapp\",\n        \"username\" : \"appuser\",\n        \"password\" : \"secretpassword\"\n    }\n}\n</code></pre></p> <p>Note</p> <p>The controller will make an API call for every single time it asks an executor to spin up a container. Please make sure to account for this in your configuration management system.</p>"},{"location":"tasks/specification/#executor-fetched-config","title":"Executor fetched Config","text":"<p>Config file can be fetched from a remote server by the executor before spinning up a container. Once fetched, the payload will be injected as a config file into the container.</p> <p>The following details are needed for this:</p> Name Option Description Type <code>type</code> Set the value to <code>EXECUTOR_HTTP_FETCH</code> Local Filename <code>localFilename</code> File name for the config inside the container. HTTP Call Details <code>http</code> HTTP Call related details. Please refer to HTTP Call Specification for details. <p>Sample config specification: <pre><code>{\n    \"type\" : \"EXECUTOR_HTTP_FETCH\",\n    \"localFilename\" : \"/config/service.yml\",\n    \"http\" : {\n        \"protocol\" : \"HTTP\",\n        \"hostname\" : \"configserver.internal.yourdomain.net\",\n        \"port\" : 8080,\n        \"path\" : \"/configs/myapp\",\n        \"username\" : \"appuser\",\n        \"password\" : \"secretpassword\"\n    }\n}\n</code></pre></p> <p>Note</p> <p>All executors will make an API call for every single time they spin up a container for this application. Please make sure to account for this in your configuration management system.</p>"},{"location":"tasks/specification/#http-call-specification","title":"HTTP Call Specification","text":"<p>This section details the options that can set when making http calls to a configuration management system from controllers or executors.</p> <p>The following options are available for HTTP call:</p> Name Option Description Protocol <code>protocol</code> Protocol to use for upstream call. Can be <code>HTTP</code> or <code>HTTPS</code>. Hostname <code>hostname</code> Host to call. Port <code>port</code> Provide custom port. Defaults to 80 for http and 443 for https. API Path <code>path</code> Path component of the URL. Include query parameters here. Defaults to <code>/</code> HTTP Method <code>verb</code> Type of call, use <code>GET</code>, <code>POST</code> or <code>PUT</code>. Defaults to <code>GET</code>. Success Code <code>successCodes</code> List of HTTP status codes which is considered as success. Defaults to <code>[200]</code> Payload <code>payload</code> Data to be used for POST and PUT calls Connection Timeout <code>connectionTimeout</code> Timeout for upstream connection. Operation timeout <code>operationTimeout</code> Timeout for actual operation. Username <code>username</code> Username to be used basic auth. This field is masked out on the UI. Password <code>password</code> Password to be used for basic auth. This field is masked on the UI. Authorization Header <code>authHeader</code> Data to be passed in HTTP <code>Authorization</code> header. This field is masked on the UI. Additional Headers <code>headers</code> Any other headers to be passed to the upstream in the HTTP calls. This is a map of Skip SSL Checks <code>insecure</code> Skip hostname and certification checks during SSL handshake with the upstream."},{"location":"tasks/specification/#placement-policy-specification","title":"Placement Policy Specification","text":"<p>Placement policy governs how Drove deploys containers on the cluster. The following sections discuss the different placement policies available and how they can be configured to achieve optimal placement of containers.</p> <p>Warning</p> <p>All policies will work only at a <code>{appName, version}</code> combination level. They will not ensure constraints at an <code>appName</code> level. This means that for somethinge like a one per node placement, for the same <code>appName</code>, multiple containers can run on the same host if multiple deployments with different <code>version</code>s are active in a cluster. Same applies for all policies like N per host and so on.</p> <p>Important details about executor tagging</p> <ul> <li>All hosts have at-least one tag, it's own hostname.</li> <li>The <code>TAG</code> policy will consider them as valid tags. This can be used to place containers on specific hosts if needed.</li> <li>This is handled specially in all other policy types and they will consider executors having only the hostname tag as untagged.</li> <li>A host with a tag (other than host) will not have any containers running if not placed on them specifically using the <code>MATCH_TAG</code> policy</li> </ul>"},{"location":"tasks/specification/#any-placement","title":"Any Placement","text":"<p>Containers for a <code>{appName, version}</code> combination can run on any un-tagged executor host.</p> Name Option Description Policy Type <code>type</code> Put <code>ANY</code> as policy. <p>Sample: <pre><code>{\n    \"type\" : \"ANY\"\n}\n</code></pre></p> <p>Tip</p> <p>For most use-cases this is the placement policy to use.</p>"},{"location":"tasks/specification/#one-per-host-placement","title":"One Per Host Placement","text":"<p>Ensures that only one container for a particular <code>{appName, version}</code> combination is running on an executor host at a time.</p> Name Option Description Policy Type <code>type</code> Put <code>ONE_PER_HOST</code> as policy. <p>Sample: <pre><code>{\n    \"type\" : \"ONE_PER_HOST\"\n}\n</code></pre></p>"},{"location":"tasks/specification/#max-n-per-host-placement","title":"Max N Per Host Placement","text":"<p>Ensures that at most N containers for a <code>{appName, version}</code> combination is running on an executor host at a time.</p> Name Option Description Policy Type <code>type</code> Put <code>MAX_N_PER_HOST</code> as policy. Max count <code>max</code> The maximum num of containers that can run on an executor. Range: 1-64 <p>Sample: <pre><code>{\n    \"type\" : \"MAX_N_PER_HOST\",\n    \"max\": 3\n}\n</code></pre></p>"},{"location":"tasks/specification/#match-tag-placement","title":"Match Tag Placement","text":"<p>Ensures that containers for a <code>{appName, version}</code> combination are running on an executor host that has the tags as mentioned in the policy.</p> Name Option Description Policy Type <code>type</code> Put <code>MATCH_TAG</code> as policy. Max count <code>tag</code> The tag to match. <p>Sample: <pre><code>{\n    \"type\" : \"MATCH_TAG\",\n    \"tag\": \"gpu_enabled\"\n}\n</code></pre></p>"},{"location":"tasks/specification/#no-tag-placement","title":"No Tag Placement","text":"<p>Ensures that containers for a <code>{appName, version}</code> combination are running on an executor host that has no tags.</p> Name Option Description Policy Type <code>type</code> Put <code>NO_TAG</code> as policy. <p>Sample: <pre><code>{\n    \"type\" : \"NO_TAG\"\n}\n</code></pre></p> <p>Info</p> <p>The NO_TAG policy is mostly for internal use, and does not need to be specified when deploying containers that do not need any special placement logic.</p>"},{"location":"tasks/specification/#composite-policy-based-placement","title":"Composite Policy Based Placement","text":"<p>Composite policy can be used to combine policies together to create complicated placement requirements.</p> Name Option Description Policy Type <code>type</code> Put <code>COMPOSITE</code> as policy. Polices <code>policies</code> List of policies to combine Combiner <code>combiner</code> Can be <code>AND</code> and <code>OR</code> and signify all-match and any-match logic on the <code>policies</code> mentioned. <p>Sample: <pre><code>{\n    \"type\" : \"COMPOSITE\",\n    \"policies\": [\n        {\n            \"type\": \"ONE_PER_HOST\"\n        },\n        {\n            \"type\": \"MATH_TAG\",\n            \"tag\": \"gpu_enabled\"\n        }\n    ],\n    \"combiner\" : \"AND\"\n}\n</code></pre> The above policy will ensure that only one container of the relevant <code>{appName,version}</code> will run on GPU enabled machines.</p> <p>Tip</p> <p>It is easy to go into situations where no executors match complicated placement policies. Internally, we tend to keep things rather simple and use the ANY placement for most cases and maybe tags in a few places with over-provisioning or for hosts having special hardware </p>"},{"location":"tasks/specification/#environment-variables","title":"Environment variables","text":"<p>This config can be used to inject custom environment variables to containers. The values are defined as part of deployment specification, are same across the cluster and immutable to modifications from inside the container (ie any overrides from inside the container will not be visible across the cluster).</p> <p>Sample: <pre><code>{\n    \"MY_VARIABLE_1\": \"fizz\",\n    \"MY_VARIABLE_2\": \"buzz\"\n}\n</code></pre></p> <p>The following environment variables are injected by Drove to all containers:</p> Variable Name Value HOST Hostname where the container is running. This is for marathon compatibility. PORT_<code>PORT_NUMBER</code> A variable for every port specified in <code>exposedPorts</code> section. The value is the actual port on the host, the specified port is mapped to.  For example if ports 8080 and 8081 are specified, two variables called <code>PORT_8080</code> and <code>PORT_8081</code> will be injected. DROVE_EXECUTOR_HOST Hostname where container is running. DROVE_CONTAINER_ID Container that is deployed DROVE_APP_NAME App name as specified in the Application Specification DROVE_INSTANCE_ID Actual instance ID generated by Drove DROVE_APP_ID Application ID as generated by Drove DROVE_APP_INSTANCE_AUTH_TOKEN A JWT string generated by Drove that can be used by this container to call <code>/apis/v1/internal/...</code> apis. <p>Warning</p> <p>Do not pass secrets using environment variables. These variables are all visible on the UI as is. Please use Configs to inject secrets files and so on.</p>"},{"location":"tasks/specification/#logging-specification","title":"Logging Specification","text":"<p>Can be used to configure how container logs are managed on the system. </p> <p>Note</p> <p>This section affects the docker log driver. Drove will continue to stream logs to it's own logger which can be configured at executor level through the executor configuration file.</p>"},{"location":"tasks/specification/#local-logger-configuration","title":"Local Logger configuration","text":"<p>This is used to configure the <code>json-file</code> log driver.</p> Name Option Description Type <code>type</code> Set the value to <code>LOCAL</code> Max Size <code>maxSize</code> Maximum file size. Anything bigger than this will lead to rotation. Max Files <code>maxFiles</code> Maximum number of logs files to keep. Range: 1-100 Compress <code>compress</code> Enable log file compression. <p>Tip</p> <p>If <code>logging</code> section is omitted, the following configuration is applied by default: - File size: 10m - Number of files: 3 - Compression: on</p>"},{"location":"tasks/specification/#rsyslog-configuration","title":"Rsyslog configuration","text":"<p>In case suers want to stream logs to an rsyslog server, the logging configuration needs to be set to RSYSLOG mode.</p> Name Option Description Type <code>type</code> Set the value to <code>RSYSLOG</code> Server <code>server</code> URL for the rsyslog server. Tag Prefix <code>tagPrefix</code> Prefix to add at the start of a tag Tag Suffix <code>tagSuffix</code> Suffix to add at the en of a tag. <p>Note</p> <p>The default tag is the <code>DROVE_INSTANCE_ID</code>. The <code>tagPrefix</code> and <code>tagSuffix</code> will to before and after this</p>"}]}